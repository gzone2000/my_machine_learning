{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ======== 파라미터 ========\n",
    "training_steps = 22000\n",
    "display_step = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[54. 12.]\n",
      " [ 8.  0.]\n",
      " [30. 12.]\n",
      " [24. 15.]\n",
      " [46. 12.]\n",
      " [12.  0.]\n",
      " [20. 36.]\n",
      " [37. 12.]\n",
      " [40. 12.]\n",
      " [48. 24.]]\n",
      "[[800.]\n",
      " [320.]\n",
      " [600.]\n",
      " [630.]\n",
      " [700.]\n",
      " [300.]\n",
      " [920.]\n",
      " [720.]\n",
      " [700.]\n",
      " [920.]]\n"
     ]
    }
   ],
   "source": [
    "# ======== 학습데이터 ========\n",
    "xy = np.loadtxt('train.txt', unpack=True, dtype='float32')\n",
    "\n",
    "# 학습시간, 해외거주\n",
    "x_data = xy[0:-1]\n",
    "\n",
    "# 토익점수\n",
    "y_data = xy[-1]\n",
    "\n",
    "#  배열 위치 변환\n",
    "X = x_data[:].T\n",
    "print(X)\n",
    "Y = y_data.reshape(-1,1)\n",
    "print(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'Variable:0' shape=(2, 1) dtype=float32, numpy=\n",
       "array([[0.1],\n",
       "       [0.1]], dtype=float32)>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ======== W, B 초기값 설정 =========\n",
    "#W = tf.Variable(tf.random.normal((2,1)))\n",
    "#b = tf.Variable(np.random.randn(), name=\"bias\")\n",
    "W = tf.Variable(np.array([[0.1],[0.1]], dtype=np.float32))\n",
    "b = tf.Variable(1.0)\n",
    "W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[54., 12.],\n",
       "       [ 8.,  0.],\n",
       "       [30., 12.],\n",
       "       [24., 15.],\n",
       "       [46., 12.],\n",
       "       [12.,  0.],\n",
       "       [20., 36.],\n",
       "       [37., 12.],\n",
       "       [40., 12.],\n",
       "       [48., 24.]], dtype=float32)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'Variable:0' shape=(2, 1) dtype=float32, numpy=\n",
       "array([[0.1],\n",
       "       [0.1]], dtype=float32)>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10, 1), dtype=float32, numpy=\n",
       "array([[7.6000004],\n",
       "       [1.8      ],\n",
       "       [5.2      ],\n",
       "       [4.9      ],\n",
       "       [6.8      ],\n",
       "       [2.2      ],\n",
       "       [6.6000004],\n",
       "       [5.9      ],\n",
       "       [6.2      ],\n",
       "       [8.200001 ]], dtype=float32)>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.matmul(X, W) + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred1 = tf.matmul(X, W) + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10, 1), dtype=float32, numpy=\n",
       "array([[7.6000004],\n",
       "       [1.8      ],\n",
       "       [5.2      ],\n",
       "       [4.9      ],\n",
       "       [6.8      ],\n",
       "       [2.2      ],\n",
       "       [6.6000004],\n",
       "       [5.9      ],\n",
       "       [6.2      ],\n",
       "       [8.200001 ]], dtype=float32)>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[800.],\n",
       "       [320.],\n",
       "       [600.],\n",
       "       [630.],\n",
       "       [700.],\n",
       "       [300.],\n",
       "       [920.],\n",
       "       [720.],\n",
       "       [700.],\n",
       "       [920.]], dtype=float32)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10, 1), dtype=float32, numpy=\n",
       "array([[-792.4],\n",
       "       [-318.2],\n",
       "       [-594.8],\n",
       "       [-625.1],\n",
       "       [-693.2],\n",
       "       [-297.8],\n",
       "       [-913.4],\n",
       "       [-714.1],\n",
       "       [-693.8],\n",
       "       [-911.8]], dtype=float32)>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred1 - Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=469987.3>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.reduce_mean(tf.square(pred1 - Y)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "cost1 = tf.reduce_mean(tf.square(pred1 - Y)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=469987.3>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cost1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ======== Multiple Linear Regression 에서 학습될 가설 ========\n",
    "# Linear regression (Wx + b).\n",
    "def linear_regression(X):\n",
    "    return tf.matmul(X, W) + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ======== Multiple Linear Regression 에서 학습될 가설의 Cost Function ========\n",
    "# Mean square error.\n",
    "def mean_square(y_pred, y_true):\n",
    "    return tf.reduce_mean(tf.square(y_pred - y_true)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ======== Gradient Descent Algorithm 에서 Step ========\n",
    "learning_rate = 0.0006"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ======== 텐서플로우에 내장된 GradientDescentOptimizer ========\n",
    "# Stochastic Gradient Descent Optimizer.\n",
    "optimizer = tf.optimizers.SGD(learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ======== GradientDescentOptimizer ========\n",
    "# Optimization process. \n",
    "def run_optimization():\n",
    "    # Wrap computation inside a GradientTape for automatic differentiation. : 자동 미분\n",
    "    with tf.GradientTape() as g:\n",
    "        pred = linear_regression(X)\n",
    "        cost = mean_square(pred, Y)\n",
    "\n",
    "    # Compute gradients.\n",
    "    # gradients = g.gradient(cost, [W, b])\n",
    "    \n",
    "    # Update W and b following gradients.\n",
    "    # optimizer.apply_gradients(zip(gradients, [W, b]))\n",
    "    \n",
    "    weight, bias = g.gradient(cost, [W, b])\n",
    "    #print(\"1. Weight: \" ,weight)\n",
    "    #print(\"2. Bais: \" ,bias)\n",
    "\n",
    "    W.assign_sub(learning_rate * weight)\n",
    "    b.assign_sub(learning_rate * bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 1000, cost: 6970.293945, W1: 10.868449, W2: 17.642492, b: 43.998299\n",
      "step: 2000, cost: 4913.363770, W1: 10.142796, W2: 17.176504, b: 79.065842\n",
      "step: 3000, cost: 3514.061035, W1: 9.544281, W2: 16.792160, b: 107.989395\n",
      "step: 4000, cost: 2562.133789, W1: 9.050628, W2: 16.475155, b: 131.845398\n",
      "step: 5000, cost: 1914.550415, W1: 8.643466, W2: 16.213688, b: 151.521683\n",
      "step: 6000, cost: 1474.007446, W1: 8.307641, W2: 15.998034, b: 167.750610\n",
      "step: 7000, cost: 1174.312744, W1: 8.030655, W2: 15.820164, b: 181.136093\n",
      "step: 8000, cost: 970.432312, W1: 7.802197, W2: 15.673457, b: 192.176468\n",
      "step: 9000, cost: 831.737000, W1: 7.613767, W2: 15.552454, b: 201.282425\n",
      "step: 10000, cost: 737.386047, W1: 7.458352, W2: 15.452651, b: 208.792938\n",
      "step: 11000, cost: 673.197388, W1: 7.330166, W2: 15.370335, b: 214.987625\n",
      "step: 12000, cost: 629.532227, W1: 7.224438, W2: 15.302441, b: 220.096954\n",
      "step: 13000, cost: 599.826294, W1: 7.137233, W2: 15.246441, b: 224.311142\n",
      "step: 14000, cost: 579.617920, W1: 7.065308, W2: 15.200253, b: 227.786987\n",
      "step: 15000, cost: 565.870300, W1: 7.005985, W2: 15.162158, b: 230.653809\n",
      "step: 16000, cost: 556.518677, W1: 6.957055, W2: 15.130737, b: 233.018387\n",
      "step: 17000, cost: 550.155701, W1: 6.916698, W2: 15.104821, b: 234.968628\n",
      "step: 18000, cost: 545.827759, W1: 6.883412, W2: 15.083446, b: 236.577301\n",
      "step: 19000, cost: 542.883667, W1: 6.855957, W2: 15.065815, b: 237.903976\n",
      "step: 20000, cost: 540.880676, W1: 6.833314, W2: 15.051275, b: 238.998230\n",
      "step: 21000, cost: 539.517944, W1: 6.814638, W2: 15.039282, b: 239.900864\n",
      "step: 22000, cost: 538.591309, W1: 6.799232, W2: 15.029388, b: 240.645233\n"
     ]
    }
   ],
   "source": [
    "# Run training for the given number of steps.\n",
    "for step in range(1, training_steps + 1):\n",
    "    # Run the optimization to update W and b values.\n",
    "    run_optimization()\n",
    "    \n",
    "    if step % display_step == 0:\n",
    "        pred = linear_regression(X)\n",
    "        cost = mean_square(pred, Y)\n",
    "        print(\"step: %i, cost: %f, W1: %f, W2: %f, b: %f\" % (step, cost, W[0].numpy(), W[1].numpy(), b.numpy()))\n",
    "        #print(\"예측값 : {}\".format(pred.numpy()))\n",
    "        \n",
    "        '''\n",
    "        print(\"cost type: {}\".format(type(cost)))\n",
    "        print(\"W type: {}\".format(type(W)))\n",
    "        print(\"b type: {}\".format(type(b)))\n",
    "        print(\"pred type: {}\".format(type(pred)))\n",
    "        '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30 시간, 10 개월 해외거주: 594.916016 점\n",
      "2 시간, 24 개월 해외거주: 614.948975 점\n"
     ]
    }
   ],
   "source": [
    "# ======== 학습된 우리의 프로그램에 예측 문의 ========\n",
    "\n",
    "sample = np.array([\n",
    "    [30, 10] \n",
    "], dtype=np.float32)\n",
    "\n",
    "sample1 = np.array([\n",
    "    [2, 24] \n",
    "], dtype=np.float32)\n",
    "\n",
    "# 30 시간 공부하고 10개월 해외에서 거주했을 경우 토익점수 예측\n",
    "print (\"%i 시간, %i 개월 해외거주: %f 점\" % (sample[0,0], sample[0,1], linear_regression(sample).numpy()))\n",
    "print (\"%i 시간, %i 개월 해외거주: %f 점\" % (sample1[0,0], sample1[0,1], linear_regression(sample1).numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
