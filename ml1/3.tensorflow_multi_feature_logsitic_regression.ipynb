{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ======== 파라미터 ========\n",
    "training_steps = 22000\n",
    "display_step = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[54. 12.]\n",
      " [ 8.  0.]\n",
      " [30. 12.]\n",
      " [24. 15.]\n",
      " [46. 12.]\n",
      " [12.  0.]\n",
      " [20. 36.]\n",
      " [37. 12.]\n",
      " [40. 12.]\n",
      " [48. 24.]]\n",
      "[[0. 1. 0. 0.]\n",
      " [0. 0. 0. 1.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 0. 0. 1.]\n",
      " [1. 0. 0. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [0. 0. 1. 0.]\n",
      " [1. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "# ======== 학습데이터 ========\n",
    "xy = np.loadtxt('softmax_data.txt', unpack=True, dtype='float32')\n",
    "\n",
    "# 학습시간, 해외거주(월)\n",
    "x_data = xy[0:2]\n",
    "\n",
    "# 영어 학점 : 0 : A, 1: B , 2: C, 3: D\n",
    "y_data = xy[2:]\n",
    "\n",
    "#  배열 위치 변환\n",
    "X = x_data[:].T\n",
    "print(X)\n",
    "Y = y_data.T\n",
    "print(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'Variable:0' shape=(2, 4) dtype=float32, numpy=\n",
       "array([[0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.]], dtype=float32)>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ======== W, B 초기값 설정 =========\n",
    "#W = tf.Variable(tf.random.normal((2,1)))\n",
    "#b = tf.Variable(np.random.randn(), name=\"bias\")\n",
    "W = tf.Variable(tf.zeros([2, 4]))\n",
    "b = tf.Variable(1.0)\n",
    "W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[54., 12.],\n",
       "       [ 8.,  0.],\n",
       "       [30., 12.],\n",
       "       [24., 15.],\n",
       "       [46., 12.],\n",
       "       [12.,  0.],\n",
       "       [20., 36.],\n",
       "       [37., 12.],\n",
       "       [40., 12.],\n",
       "       [48., 24.]], dtype=float32)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'Variable:0' shape=(2, 4) dtype=float32, numpy=\n",
       "array([[0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.]], dtype=float32)>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10, 4), dtype=float32, numpy=\n",
       "array([[1., 1., 1., 1.],\n",
       "       [1., 1., 1., 1.],\n",
       "       [1., 1., 1., 1.],\n",
       "       [1., 1., 1., 1.],\n",
       "       [1., 1., 1., 1.],\n",
       "       [1., 1., 1., 1.],\n",
       "       [1., 1., 1., 1.],\n",
       "       [1., 1., 1., 1.],\n",
       "       [1., 1., 1., 1.],\n",
       "       [1., 1., 1., 1.]], dtype=float32)>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.matmul(X, W) + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "hypothesis = tf.nn.softmax(tf.matmul(X, W)+b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10, 4), dtype=float32, numpy=\n",
       "array([[0.25, 0.25, 0.25, 0.25],\n",
       "       [0.25, 0.25, 0.25, 0.25],\n",
       "       [0.25, 0.25, 0.25, 0.25],\n",
       "       [0.25, 0.25, 0.25, 0.25],\n",
       "       [0.25, 0.25, 0.25, 0.25],\n",
       "       [0.25, 0.25, 0.25, 0.25],\n",
       "       [0.25, 0.25, 0.25, 0.25],\n",
       "       [0.25, 0.25, 0.25, 0.25],\n",
       "       [0.25, 0.25, 0.25, 0.25],\n",
       "       [0.25, 0.25, 0.25, 0.25]], dtype=float32)>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hypothesis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ======== logistic Regression 에서 학습될 가설 ========\n",
    "# Logistic regression (Wx + b).\n",
    "def logistic_regression(x):\n",
    "    # Apply softmax to normalize the logits to a probability distribution.\n",
    "    return tf.nn.softmax(tf.matmul(x, W) + b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ======== logistic Regression 에서 학습될 가설의 Cost Function ========\n",
    "# Cross-Entropy loss function.\n",
    "def cross_entropy(y_pred, y_true):\n",
    "    # Clip prediction values to avoid log(0) error.\n",
    "    y_pred = tf.clip_by_value(y_pred, 1e-9, 1.)\n",
    "    # Compute cross-entropy.\n",
    "    return tf.reduce_mean(-tf.reduce_sum(y_true * tf.math.log(y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ======== logistic Regression 에서 학습될 가설의 정확도 ========\n",
    "# Accuracy metric.\n",
    "def accuracy(y_pred, y_true):\n",
    "    # Predicted class is the index of highest score in prediction vector (i.e. argmax).    \n",
    "    #correct_prediction = tf.equal(tf.argmax(y_pred), tf.cast(y_true, tf.int64))\n",
    "    correct_prediction = tf.equal(tf.argmax(y_pred,1), tf.cast(tf.argmax(y_true,1), tf.int64))\n",
    "    return tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10, 4), dtype=float32, numpy=\n",
       "array([[1.6116926e-04, 9.7233433e-01, 2.4560453e-02, 2.9440953e-03],\n",
       "       [3.6819370e-06, 1.7326104e-02, 1.3216116e-05, 9.8265702e-01],\n",
       "       [2.3282214e-01, 1.3479804e-08, 7.6717782e-01, 2.2372612e-16],\n",
       "       [6.6062069e-01, 3.7646491e-16, 3.3937931e-01, 7.7874670e-29],\n",
       "       [2.2352900e-02, 2.8657768e-02, 9.4898778e-01, 1.5299511e-06],\n",
       "       [7.2359536e-09, 2.3357859e-03, 4.9208190e-08, 9.9766421e-01],\n",
       "       [9.9950230e-01, 0.0000000e+00, 4.9763761e-04, 0.0000000e+00],\n",
       "       [9.0240560e-02, 8.5429474e-06, 9.0975088e-01, 4.8543379e-12],\n",
       "       [5.7862677e-02, 1.3056846e-04, 9.4200677e-01, 3.3728598e-10],\n",
       "       [3.8511446e-01, 3.9992038e-21, 6.1488557e-01, 0.0000000e+00]],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = logistic_regression(X)\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10,), dtype=int64, numpy=array([1, 3, 2, 0, 2, 3, 0, 2, 2, 2], dtype=int64)>"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.argmax(pred,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10,), dtype=int64, numpy=array([1, 3, 2, 2, 2, 3, 0, 2, 2, 0], dtype=int64)>"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.argmax(Y,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10, 4), dtype=int64, numpy=\n",
       "array([[0, 1, 0, 0],\n",
       "       [0, 0, 0, 1],\n",
       "       [0, 0, 1, 0],\n",
       "       [0, 0, 1, 0],\n",
       "       [0, 0, 1, 0],\n",
       "       [0, 0, 0, 1],\n",
       "       [1, 0, 0, 0],\n",
       "       [0, 0, 1, 0],\n",
       "       [0, 0, 1, 0],\n",
       "       [1, 0, 0, 0]], dtype=int64)>"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.cast(Y, tf.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10,), dtype=bool, numpy=\n",
       "array([ True,  True,  True, False,  True,  True,  True,  True,  True,\n",
       "       False])>"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.equal(tf.argmax(pred,1), tf.cast(tf.argmax(Y,1), tf.int64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ======== Gradient Descent Algorithm 에서 Step ========\n",
    "learning_rate = 0.0006"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ======== 텐서플로우에 내장된 GradientDescentOptimizer ========\n",
    "# Stochastic Gradient Descent Optimizer.\n",
    "optimizer = tf.optimizers.SGD(learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ======== GradientDescentOptimizer ========\n",
    "# Optimization process. \n",
    "def run_optimization(x, y):\n",
    "    # Wrap computation inside a GradientTape for automatic differentiation.\n",
    "    with tf.GradientTape() as g:\n",
    "        pred = logistic_regression(x)\n",
    "        loss = cross_entropy(pred, y)\n",
    "\n",
    "    # Compute gradients.\n",
    "    gradients = g.gradient(loss, [W, b])\n",
    "    \n",
    "    # Update W and b following gradients.\n",
    "    optimizer.apply_gradients(zip(gradients, [W, b]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 1000, loss: 2.553336, accuracy: 0.800000\n",
      "step: 2000, loss: 2.551781, accuracy: 0.800000\n",
      "step: 3000, loss: 2.550288, accuracy: 0.800000\n",
      "step: 4000, loss: 2.548855, accuracy: 0.800000\n",
      "step: 5000, loss: 2.547474, accuracy: 0.800000\n",
      "step: 6000, loss: 2.546142, accuracy: 0.800000\n",
      "step: 7000, loss: 2.544870, accuracy: 0.800000\n",
      "step: 8000, loss: 2.543639, accuracy: 0.800000\n",
      "step: 9000, loss: 2.542453, accuracy: 0.800000\n",
      "step: 10000, loss: 2.541309, accuracy: 0.800000\n",
      "step: 11000, loss: 2.540206, accuracy: 0.800000\n",
      "step: 12000, loss: 2.539138, accuracy: 0.800000\n",
      "step: 13000, loss: 2.538107, accuracy: 0.800000\n",
      "step: 14000, loss: 2.537115, accuracy: 0.800000\n",
      "step: 15000, loss: 2.536148, accuracy: 0.800000\n",
      "step: 16000, loss: 2.535210, accuracy: 0.800000\n",
      "step: 17000, loss: 2.534309, accuracy: 0.800000\n",
      "step: 18000, loss: 2.533437, accuracy: 0.800000\n",
      "step: 19000, loss: 2.532585, accuracy: 0.800000\n",
      "step: 20000, loss: 2.531758, accuracy: 0.800000\n",
      "step: 21000, loss: 2.530962, accuracy: 0.800000\n",
      "step: 22000, loss: 2.530184, accuracy: 0.800000\n"
     ]
    }
   ],
   "source": [
    "# Run training for the given number of steps.\n",
    "for step in range(1, training_steps + 1):\n",
    "    # Run the optimization to update W and b values.\n",
    "    run_optimization(X, Y)\n",
    "\n",
    "    if step % display_step == 0:\n",
    "        pred = logistic_regression(X)\n",
    "        loss = cross_entropy(pred, Y)\n",
    "        acc = accuracy(pred, Y)\n",
    "        print(\"step: %i, loss: %f, accuracy: %f\" % (step, loss, acc))\n",
    "        #print(\"step: %i, loss: %f\" % (step, loss))\n",
    "        \n",
    "        '''\n",
    "        print(\"cost type: {}\".format(type(cost)))\n",
    "        print(\"W type: {}\".format(type(W)))\n",
    "        print(\"b type: {}\".format(type(b)))\n",
    "        print(\"pred type: {}\".format(type(pred)))\n",
    "        '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30 시간, 10 개월 해외거주: C \n"
     ]
    }
   ],
   "source": [
    "# ======== 학습된 우리의 프로그램에 예측 문의 ========\n",
    "sample = np.array([\n",
    "    [30, 10] \n",
    "], dtype=np.float32)\n",
    "\n",
    "dict = {\n",
    "    0 : \"A\",\n",
    "    1 : \"B\",\n",
    "    2 : \"C\",\n",
    "    3 : \"D\"\n",
    "}\n",
    "\n",
    "# 30 시간 공부하고 10개월 해외에서 거주했을 경우 영어학점 예측\n",
    "predictions = logistic_regression(sample)\n",
    "result = np.argmax(predictions.numpy())\n",
    "print (\"%i 시간, %i 개월 해외거주: %s \" % (sample[0,0], sample[0,1], dict[result]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
