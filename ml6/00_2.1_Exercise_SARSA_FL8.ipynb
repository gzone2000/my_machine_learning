{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"00_2.1_Exercise_SARSA_FL8.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyPUEvvUzsyYChAEKZe1mwco"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"F5tABggTVKQw","colab_type":"text"},"source":["# SARSA & Q - Learning\n","\n","# 연습데이터 : Frozen Lake\n","![좋은거](https://encrypted-tbn0.gstatic.com/images?q=tbn%3AANd9GcSqnklD5CDrIqDgS28YCAcmQkfBhJVvYirrRbZjmZeta5Dfx4_e&usqp=CAU)\n","\n","**학습목표**\n","\n","1. SARSA의 업데이트 맛 본다.\n","2. Q-learning의 업데이트를 맛 본다.\n","3. 일단 코드 짤 수 있다."]},{"cell_type":"markdown","metadata":{"id":"uJB96tIRZfeT","colab_type":"text"},"source":["# 필요 라이브러리 불러오기\n","\n","1. 이런 연습에서는 딱히 비디오 영상이 필요하지 않다."]},{"cell_type":"code","metadata":{"id":"Bi_Z3_kaZRot","colab_type":"code","colab":{}},"source":["!pip install gym"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"MVEK7ArIZoeN","colab_type":"code","colab":{}},"source":["import numpy as np\n","import gym"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ttRBaI2WZqcX","colab_type":"text"},"source":["# 사용할 환경 불러오기"]},{"cell_type":"code","metadata":{"id":"LzYjwZKRZsCV","colab_type":"code","colab":{}},"source":["# gym.envs.registration.register(\n","#     id=\"FrozenLake-v3\", entry_point='gym.envs.toy_text:FrozenLakeEnv',\n","#     kwargs={'map_name': '4x4', 'is_slippery': False}\n","# )\n","\n","gym.envs.registration.register(\n","    id=\"FrozenLake-v8\", entry_point='gym.envs.toy_text:FrozenLakeEnv',\n","    kwargs={'map_name': '8x8', 'is_slippery': True}\n",")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"86nb4VeAaACM","colab_type":"code","colab":{}},"source":["# env = gym.make('FrozenLake-v3')\n","env = gym.make('FrozenLake-v8')\n","print('observation space:', env.observation_space)\n","print('action space:', env.action_space)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"vrgrAKT09lsD","colab_type":"text"},"source":["# SARSA와, Q-learning 준비 해보기\n","\n","**핵심 코드**\n","1. SARSA : S,A,R,S,A 가 끝나면 Q업데이트!\n","```\n","Q[s,a] = Q[s,a] + alpha * ((r + gama* Q[s1,a1]) - Q[s,a])\n","```\n","2. Q-Learning : S,A,R,S 후 max A, 그다음 Q업데이트!\n","```\n","Q[s,a] = Q[s,a] + alpha*(r + gama*np.max(Q[s1,:]) - Q[s,a])\n","```\n"]},{"cell_type":"markdown","metadata":{"id":"sq0VaqTqfrW7","colab_type":"text"},"source":["# I. SARSA"]},{"cell_type":"markdown","metadata":{"id":"nfORhpDsayLQ","colab_type":"text"},"source":["### 1. Q-Table을 준비하자.\n","\n","* Q = np.zeros([state의 수, action의 수])\n","* 활용 예시\n","    * Q[2, 3]에는 10이 담겨있음.\n","    * Q[2, 1]에는 5가 담겨있음.\n","    * 2번 state에선 3번 액션이 1번 액션보다 2배 가치 있음!\n","\n","* env.action_space.n, env.observation_space.n 이용"]},{"cell_type":"code","metadata":{"id":"sYjtpRrqd7by","colab_type":"code","colab":{}},"source":["env.observation_space, env.action_space"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"5Z1Q9xpMeoVK","colab_type":"code","colab":{}},"source":["## Your Code Here\n","\n","\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"E4tstupmfLux","colab_type":"code","colab":{}},"source":["print(Q)\n","# for rows in Q.reshape([4,4,4]):\n","#     print(*rows)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"722t9WpVfpEp","colab_type":"text"},"source":["### 2. parameter들"]},{"cell_type":"code","metadata":{"id":"O1SPcVpcgNG9","colab_type":"code","colab":{}},"source":["alpha = 0.2\n","gamma = 0.999 # 할인율!\n","n_episod = 20000\n","epsilon = 0.15"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"d2gpuoQfgdbH","colab_type":"text"},"source":["### 3. SARSA!"]},{"cell_type":"code","metadata":{"id":"MNpjAB66gfj5","colab_type":"code","colab":{}},"source":["Q = np.zeros([env.observation_space.n,\n","              env.action_space.n])\n","\n","rewards_sarsa = []\n","\n","for i in range(n_episod) : \n","                   # 환경 초기화 하며 초기 state  s0를 선언\n","    done = False\n","                   # 처음엔 랜덤무브하여 a0 선택, 선언\n","\n","    while True :\n","        ## a0를 이용해 움직이고\n","        ## s1, r1, done, _를 return 받는 코드를 짜자.\n","\n","\n","        # e-greedy 방법을 구현해두자.\n","        # 행동을 선택하여 a1에 선언하자.\n","        if np.random.uniform() < epsilon :  # 무슨 뜻?\n","            a1 = env.action_space.sample()\n","        else : \n","            greedy_actions = np.argwhere(Q[s1, :] == np.amax(Q[s1, :])).reshape(-1)\n","            a1 = np.random.choice(greedy_actions) # 무슨 뜻?\n","\n","        # Update 코드를 작성해보자.\n","        # ( s0, a0, r1, s1, a1 ) 로 부터!\n","        \n","        \n","\n","        if done == True: # 종료되었으면\n","            rewards_sarsa.append(r1)\n","            env.close() # 환경 닫고.\n","            break # 멈춰야지\n","\n","        s0 = s1 # 다음 루프에선 이것이 직전 state\n","        a0 = a1 # 다음 루프에선 이것이 직전 action\n","\n","    if (i+1) % 4000 == 0 :\n","        print('===========  에피소드 : {}  ============'.format(i+1))\n","        # for rows in Q.reshape([-1,4,4]):\n","        #     print(*rows)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ktMvL2nSva8V","colab_type":"text"},"source":["### 학습 완료된 것 구경\n","### 무한 루프 주의\n","위 에서, 학습을 1 ~ 2회만 시켜보고 아래를 해봐도 좋다."]},{"cell_type":"code","metadata":{"id":"QrVEfKVtvSo7","colab_type":"code","colab":{}},"source":["s0 = env.reset()\n","done = False\n","a0 = env.action_space.sample() # 처음엔 랜덤무브\n","\n","while True :\n","    env.render()\n","    s1, r1, done, _ = env.step(a0) # 일단 움직인다.\n","\n","    greedy_actions = np.argwhere(Q[s1, :] == np.amax(Q[s1, :])).reshape(-1)\n","    a1 = np.random.choice(greedy_actions) # 무슨 뜻?\n","\n","    # 무한 루프 걸린다면 위의 두줄 주석, 아래를 주석 해제\n","    # if np.random.uniform() < epsilon :  # 무슨 뜻?\n","    #     a1 = env.action_space.sample()\n","    # else : \n","    #     greedy_actions = np.argwhere(Q[s1, :] == np.amax(Q[s1, :])).reshape(-1)\n","    #     a1 = np.random.choice(greedy_actions) # 무슨 뜻?\n","\n","\n","    if done == True: # 종료되었으면\n","        env.render()\n","        env.close() # 환경 닫고.\n","        break # 멈춰야지\n","\n","    s0 = s1 # 다음 루프에선 이것이 직전 state\n","    a0 = a1 # 다음 루프에선 이것이 직전 action"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"cphzXgO-v1c_","colab_type":"text"},"source":["### SARSA 학습코드를 보고, 진행 순서를 정리해보자."]},{"cell_type":"code","metadata":{"id":"On5jsUxHv-sA","colab_type":"code","colab":{}},"source":[""],"execution_count":null,"outputs":[]}]}