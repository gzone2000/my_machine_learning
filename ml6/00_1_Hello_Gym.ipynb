{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"00_1_Hello_Gym.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyMHaJl7FLYgztMRGbVCunJ3"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"xdcuYkEeumQf","colab_type":"text"},"source":["# 강화학습 입문자의 부트 캠프!\n","# [GYM](https://gym.openai.com/)\n","\n","* gym의 [document](https://gym.openai.com/docs/)"]},{"cell_type":"markdown","metadata":{"id":"Q0kqz8Xhv3YY","colab_type":"text"},"source":["# 필요한 라이브러리들 설치"]},{"cell_type":"code","metadata":{"id":"pevkxgppv5Pk","colab_type":"code","colab":{}},"source":["%%time\n","## 약 25초 ~30초 소요\n","!pip install pyvirtualdisplay \n","!apt-get install -y xvfb python-opengl ffmpeg\n","!pip install gym\n","!pip install box2d-py\n","#!pip install pyglet==1.3.2\n","!pip install pyglet"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"JEPscYu1v8Co","colab_type":"code","colab":{}},"source":["%tensorflow_version 2.x\n","import gym\n","from gym import logger as gymlogger\n","from gym.wrappers import Monitor\n","gymlogger.set_level(40) #error only\n","import numpy as np\n","import matplotlib.pyplot as plt\n","%matplotlib inline\n","import glob\n","import io\n","import base64\n","from IPython.display import HTML\n","from IPython import display as ipythondisplay\n","from pyvirtualdisplay import Display"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"s7RrH9VqwJnM","colab_type":"code","colab":{}},"source":["display = Display(visible=0, size=(1400, 900))\n","display.start()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"qlbxNSFhxJne","colab_type":"text"},"source":["# 비디오 녹화를 위한 함수 제작\n"]},{"cell_type":"code","metadata":{"id":"-e5-bHL_wLFD","colab_type":"code","colab":{}},"source":["\"\"\"\n","Utility functions to enable video recording of gym environment and displaying it\n","To enable video, just do \"env = wrap_env(env)\"\"\n","\"\"\"\n","\n","def show_video():\n","  mp4list = glob.glob('video/*.mp4')\n","  if len(mp4list) > 0:\n","    mp4 = mp4list[-1]\n","    video = io.open(mp4, 'r+b').read()\n","    encoded = base64.b64encode(video)\n","    ipythondisplay.display(HTML(data='''<video alt=\"test\" autoplay \n","                loop controls style=\"height: 400px;\">\n","                <source src=\"data:video/mp4;base64,{0}\" type=\"video/mp4\" />\n","             </video>'''.format(encoded.decode('ascii'))))\n","  else: \n","    print(\"Could not find video\")\n","    \n","\n","def wrap_env(env):\n","  env = Monitor(env, './video', force=True)\n","  return env"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"vD19ni68xRCV","colab_type":"text"},"source":["# 첫만남 I : Frozen Lake\n","\n","얜 딱히 비디오를 관찰할 것이.."]},{"cell_type":"code","metadata":{"id":"atdGwhd_zHNn","colab_type":"code","colab":{}},"source":["import gym\n","gym.envs.registration.register(\n","    id=\"FrozenLake-v3\", entry_point='gym.envs.toy_text:FrozenLakeEnv',\n","    kwargs={'map_name': '4x4', 'is_slippery': False}\n",")\n","\n","# gym.envs.registration.register(\n","#     id=\"FrozenLake-v8\", entry_point='gym.envs.toy_text:FrozenLakeEnv',\n","#     kwargs={'map_name': '8x8', 'is_slippery': True}\n","# )"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"VbwgMahcyyGJ","colab_type":"code","colab":{}},"source":["env = wrap_env(gym.make('FrozenLake-v3'))\n","# env = wrap_env(gym.make('FrozenLake-v8'))\n","print('observation space:', env.observation_space)\n","print('action space:', env.action_space)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"_ZkMBxFNzDls","colab_type":"code","colab":{}},"source":["# 반복실행 해볼 것\n","# action_space에서 랜덤한 액션을 막 뽑는것\n","env.action_space.sample()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"9qMDf-y20Q7b","colab_type":"code","colab":{}},"source":["env.render() # 현재 문제의 상황을 '눈으로'볼 수 있게 해준다.\n","print('-----state 설명-----')\n","print('S : starting point, safe')\n","print('F : frozen surface, safe')\n","print('H : hole, fall to your doom')\n","print('G : goal, where the frisbee is located')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"rzhrtDzAzjVO","colab_type":"code","colab":{}},"source":["print('G에 도착도 해보고, H에 빠져도 보자.')\n","init_state = env.reset()  # 환경 초기화, 매번 새로운 환경에서 출발해야 하니까!\n","print('초기 위치 : {}'.format(init_state))\n","done = False \n","action_controls = ['a', 's', 'd', 'w'] # 왼쪽, 아래, 오른쪽, 위\n","\n","while not done:\n","    env.render()  # 상황을 눈으로 보고.\n","\n","    key = input() # 키 a,s,d,w 를 입력받아서\n","    if key not in action_controls: # 혹시 모를 안전장치\n","        print(\"왼쪽 : a, 아래 : s, 오른쪽 : d, 위 : w\")\n","        continue\n","    \n","    action = action_controls.index(key)  #여러분의 액션을 0,1,2,3 으로 바꾸어줌.\n","\n","    state, reward, done, info = env.step(action)\n","    print('현재 위치 : {}, 방금 받은 reward : {}, episode 끝? : {}'.format(state, reward, done))\n","env.close()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Vz7O6E8E4Taj","colab_type":"text"},"source":["# 핵심적인 내용을 정리해보자.\n","\n","1. env = wrap_env(gym.make('FrozenLake-v3')) # 환경 만들기\n","    * env.observation_space : 답을 적자.\n","    * env.action_space : 답을 적자.\n","2. env.reset() 의 역할을 적자.\n","    * 무엇을 반환해주는가 : \n","    * 어떤 기능을 하는가 :\n","3. env.render() : 역할을 적자.\n","4. env.step( ) :\n","    * 무엇을 인풋으로 받는가.\n","    * 무슨 기능을 하는가? :\n","        1. state : 무엇을 return해준 것인가?\n","        2. reward : 무엇을 return해준 것인가?\n","        3. done : episode가 종료되었는지 알려줌.\n","        4. info : useful한 정보지만, evaluation때는 사용해선 안됨.\n","5. env.close() : 이걸 해줘야 뒤에서 도는게 다 멈춰진다."]},{"cell_type":"markdown","metadata":{"id":"xwY5RAlA9B3z","colab_type":"text"},"source":["# 첫만남 II : Cartpole\n","\n","env.render()와 위 내용을 참고하면 frozen lake처럼 직접 action을 키보드로 입력해가며 할 수 있지만.. 추천하지 않음"]},{"cell_type":"markdown","metadata":{"id":"ddWGfVs89S1q","colab_type":"text"},"source":["## Q1. 'FrozenLake-v3'대신 'CartPole-v1'를 불러와보자.\n","[이 문서의 Description을 읽고 답하자](https://github.com/openai/gym/blob/master/gym/envs/classic_control/cartpole.py)\n","1. observation_space : 무엇을 의미?\n","2. action space : 무엇을 의미?"]},{"cell_type":"code","metadata":{"id":"FnFhB2Sh-fi-","colab_type":"code","colab":{}},"source":["### your code\n","env = wrap_env(gym.make(         ))\n","print('observation space:', env.observation_space)\n","print('action space:', env.action_space)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"fuHQG921_mum","colab_type":"text"},"source":["## Q2. 아래 코드를 완성하시오.\n","\n","* action 에는 env.action_space.sample()를 이용하자.\n","* 실행하고. 일단 관찰!"]},{"cell_type":"code","metadata":{"id":"ziBZR0Mq_nKq","colab_type":"code","colab":{}},"source":["init_state = env.reset()  ##리셋\n","\n","for t in range(1000):\n","    action = env.             ## 랜덤 액션 \n","    env.render()\n","    observation, reward, done, info =       ###\n","    if done: \n","      break;\n","            \n","print('steps: ', t)\n","env.close()\n","show_video()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"rFV_9o4vBhi6","colab_type":"text"},"source":["## Q3. 아래 observation은 무엇을 의미하는가? -재확인"]},{"cell_type":"code","metadata":{"id":"dsrPec8X-zFM","colab_type":"code","colab":{}},"source":["print(observation)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"V2cJ1uZABl2F","colab_type":"text"},"source":["# 첫만남 III : pacman!?"]},{"cell_type":"code","metadata":{"id":"QxUHeLKHB1Vl","colab_type":"code","colab":{}},"source":["# 수정 금지\n","!apt-get update > /dev/null 2>&1\n","!apt-get install cmake > /dev/null 2>&1\n","!pip install --upgrade setuptools 2>&1\n","!pip install ez_setup > /dev/null 2>&1\n","!pip install gym[atari] > /dev/null 2>&1"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"wwvk6RxmCK10","colab_type":"text"},"source":["## Q1. 'FrozenLake-v3'대신 'MsPacman-v0'를 불러와보자.\n","[이문서를 참고 하여..](https://gym.openai.com/envs/MsPacman-v0/)\n","1. observation_space : 무엇을 의미?\n","2. action space : 무엇을 의미? (이건 git보는 것이 좋음)"]},{"cell_type":"code","metadata":{"id":"mdgOxPobCagb","colab_type":"code","colab":{}},"source":["env = wrap_env(gym.make(\"MsPacman-v0\"))\n","print('observation space:', env.observation_space)\n","print('action space:', env.action_space)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"h5mXmR8nEPpc"},"source":["## Q2. 아래 코드를 완성하시오.\n","\n","* action 에는 env.action_space.sample()를 이용하자.\n","* 실행하고. 일단 관찰!"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"ZhJVmcj7EPpd","colab":{}},"source":["init_state = env.reset()  ##리셋\n","\n","while True :\n","    env.render()\n","    action =                ## 랜덤 액션 \n","    observation, reward, done, info =     # 스텝을 밟자.\n","    if done: \n","      break;\n","        \n","env.close()\n","show_video()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"5nkvZkQyEYHI","colab_type":"text"},"source":["# 첫만남 IV : Assault-v0\n","\n","CartPole 불러온 것을 참고하여, 랜덤 액션을 취하는 agent의 episode를 녹화한 영상을 출력하시오."]},{"cell_type":"code","metadata":{"id":"rBHuFUFPG2jo","colab_type":"code","colab":{}},"source":["env = wrap_env(gym.make(\"Assault-v0\"))\n","print('observation space:', env.observation_space)\n","print('action space:', env.action_space)\n","\n","state = env.reset()\n","for t in range(1000):\n","    ####################\n","    ## Your Code here ##\n","    ####################\n","\n","    \n","    if done: \n","      break;\n","            \n","print('steps: ', t)\n","env.close()\n","show_video()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"2z0E2uk3G3XT","colab_type":"text"},"source":["# 첫만남 V : Atari BREAK OUT!!\n","\n","Assault-v0를 참고하여 ,랜덤 액션을 취하는 agent의 episode를 녹화한 영상을 출력하시오\n","* 'Breakout-v0'\n","\n"]},{"cell_type":"code","metadata":{"id":"PMsEy6rjHOlb","colab_type":"code","colab":{}},"source":["env = wrap_env(gym.make(\"Breakout-v0\"))\n","print('observation space:', env.observation_space)\n","print('action space:', env.action_space)\n","\n","####################\n","## Your Code here ##\n","####################"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"vk9RkMXlHeQ4","colab_type":"text"},"source":["# 첫만남 VI : LunarLander-v2\n","\n","* Assault-v0를 참고하여 ,랜덤 액션을 취하는 agent의 episode를 녹화한 영상을 출력하시오\n","* rewards_list = [] 선언\n","    * 시간에 따른 reward를 append\n","    * 영상 출력후에 시각화"]},{"cell_type":"code","metadata":{"id":"03_UjqK_IA2a","colab_type":"code","colab":{}},"source":["env = wrap_env(gym.make(\"LunarLander-v2\"))\n","print('observation space:', env.observation_space)\n","print('action space:', env.action_space)\n","\n","rewards_list = []\n","state = env.reset()\n","for t in range(1000):\n","    ###################\n","    ## Your Code here ##\n","    ####################\n","\n","\n","\n","    rewards_list.append(reward)\n","    if done: \n","      break;\n","            \n","print('steps: ', t)\n","env.close()\n","show_video()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"EqkBpAqRI1g6","colab_type":"code","colab":{}},"source":["plt.figure(figsize=(8,5))\n","plt.plot(np.arange(1, len(rewards_list)+1), rewards_list)\n","plt.ylabel('rewards')\n","plt.xlabel('steps #')\n","plt.show()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"jzCmuuuQJEqa","colab_type":"text"},"source":["# 기타 나머지 더 맛 봐보기"]},{"cell_type":"code","metadata":{"id":"okdvcclpJIpD","colab_type":"code","colab":{}},"source":["env = wrap_env(gym.make(\"BipedalWalker-v3\"))\n","print('observation space:', env.observation_space)\n","print('action space:', env.action_space)\n","\n","state = env.reset()\n","for t in range(1000):\n","    action = env.action_space.sample() # your agent here (this takes random actions)\n","    env.render()\n","    observation, reward, done, info = env.step(action)\n","\n","    if done: \n","      break;\n","            \n","print('steps: ', t)\n","env.close()\n","show_video()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"JKW8zb2VJKgM","colab_type":"code","colab":{}},"source":["env = wrap_env(gym.make(\"CarRacing-v0\"))\n","print('observation space:', env.observation_space)\n","print('action space:', env.action_space)\n","\n","state = env.reset()\n","for t in range(1000):\n","    action = env.action_space.sample() # your agent here (this takes random actions)\n","    env.render()\n","    observation, reward, done, info = env.step(action)\n","\n","    if done: \n","      break;\n","            \n","print('steps: ', t)\n","env.close()\n","show_video()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Xrj_2jyOJXxz","colab_type":"text"},"source":["# 쏘닉!\n","\n","![소닉](https://file.bodnara.co.kr/logo/insidelogo.php?image=%2Fhttp%3A%2F%2Ffile.bodnara.co.kr%2Fwebedit%2Fnews%2F2015%2F1575255863-sonic_movie_5m.jpg)"]},{"cell_type":"code","metadata":{"id":"sOHedNodLAMD","colab_type":"code","colab":{}},"source":["# 약 1 ~ 2분 걸림\n","!apt-get install pkg-config lua5.1 build-essential libav-tools git\n","!pip install tqdm retrowrapper gym-retro\n","!pip install -U git+git://github.com/frenchie4111/dumbrain.git"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"eSPE4vOeLLI2","colab_type":"code","colab":{}},"source":["# Don't run this command unless you already own the games, otherwise you are pirating :)\n","!python -m dumbrain.rl.retro_contest.install_games http://aiml.mikelyons.org/datasets/sonic/Sonic%20Roms.zip"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"icHAo-z9LNI-","colab_type":"code","colab":{}},"source":["!pip install gym-retro"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"KzqJQY1WLQdQ","colab_type":"code","colab":{}},"source":["import retro\n","list( filter( lambda game: game.startswith( 'Sonic' ), retro.data.list_games() ) )\n","# retro.data.lisg_games()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"iP-GMEKrPfN0","colab_type":"code","colab":{}},"source":["# env = retro.make(game='SonicTheHedgehog2-Genesis',\n","#     state='MetropolisZone.Act1', record='.')\n","import retrowrapper\n","\n","env = retrowrapper.RetroWrapper(\n","    game='SonicTheHedgehog2-Genesis',\n","    state='MetropolisZone.Act1' ,\n","    record='.'\n",")"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"OtIhuHJhLqut","colab_type":"code","colab":{}},"source":["# 시간좀 걸림\n","print('observation space:', env.observation_space)\n","print('action space:', env.action_space)\n","\n","state = env.reset()\n","for t in range(1000):\n","    action = env.action_space.sample() # your agent here (this takes random actions)\n","    # env.render()\n","    observation, reward, done, info = env.step(action)\n","\n","    if done: \n","      break;\n","            \n","print('steps: ', t)\n","env.close()\n","# show_video()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Fz1yAyFEL9M9","colab_type":"code","colab":{}},"source":["## 마지막 순간\n","plt.figure(figsize=(100,142))\n","plt.imshow(observation)\n","plt.show()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ovnHe5RqS1BC","colab_type":"code","colab":{}},"source":["!python /usr/local/lib/python3.6/dist-packages/retro/scripts/playback_movie.py /content/SonicTheHedgehog2-Genesis-MetropolisZone.Act1-000000.bk2"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"iuligBJ-TMoT","colab_type":"code","colab":{}},"source":["def show_retro():\n","  mp4list = glob.glob('*.mp4')\n","  if len(mp4list) > 0:\n","    mp4 = mp4list[0]\n","    video = io.open(mp4, 'r+b').read()\n","    encoded = base64.b64encode(video)\n","    ipythondisplay.display(HTML(data='''<video alt=\"test\" autoplay \n","                loop controls style=\"height: 400px;\">\n","                <source src=\"data:video/mp4;base64,{0}\" type=\"video/mp4\" />\n","             </video>'''.format(encoded.decode('ascii'))))\n","  else: \n","    print(\"Could not find video\")"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"LbVKwTgpTe7q","colab_type":"code","colab":{}},"source":["show_retro()"],"execution_count":0,"outputs":[]}]}