# kind 사이트 크롤링 및 DB에 저장하기

# 1. kind 사이트에 접속 
# 2. 시작 날짜, 종료 날짜 입력하고 검색
# 3. 검색결과를 엑셀 다운로드 
# 4. 엑셀 열고 DB에 저장
# 5. DB에 저장된 내용 읽어오기


# 1. 필요 라이브러리 임포트
# pip install selenium 
from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.common.keys import Keys
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
import time


# 2. 브라우저 열기 (chrome)
driver = webdriver.Chrome(r'C:\chromedriver\chromedriver.exe')


# 3. kind 사이트로 접속
driver.get('http://kind.krx.co.kr/investwarn/investattentwarnrisky.do?method=investattentwarnriskyMain')

# 4. 부라우져 기동되고 사이트 오픈 될때까지 5초간 대기
try :
    WebDriverWait(driver, 5)
except :
    pass

# 좀더 대기시간을 강제로 줌
time.sleep(1)


# 5. kind 사이트에 달력에 시작 날짜 선택 , 마우스 클릭 후 날짜 입력
# 크롬 브라우져 > F12 > 시작날짜 클릭 >오른쪽 마우스 > 검사 > F12창 '선택부분' 오른쪽 마우스 > copy > copy xpath >//*[@id="startDate"]
start_date = driver.find_element(By.XPATH, '//*[@id="startDate"]')
start_date.click()

# 칸에서 가장 끝으로 이동
start_date.send_keys(Keys.END)

# kind 사이트의 날짜를 하나씩 지우는 로직
for i in range(1, 12):
    # Keys 선언으로 가면 관련 코드 다 나와있다 (ctrl + keys 클릭)
    start_date.send_keys(Keys.BACKSPACE)
start_date.send_keys('20200101')


# 6. kind 사이트에 end 날짜 달력 선택  , 마우스 클릭 후 날짜 입력
end_date = driver.find_element(By.XPATH, '//*[@id="endDate"]')
end_date.click()

# 칸에서 가장 끝으로 이동
end_date.send_keys(Keys.END)

# kind 사이트의 날짜를 하나씩 지우는 로직
for i in range(1, 12):
    # Keys 선언으로 가면 관련 코드 다 나와있다 (ctrl + keys 클릭)
    end_date.send_keys(Keys.BACKSPACE)
end_date.send_keys('20200201')


# 7. kind 사이트에서 검색 버튼 클릭
btn_click= driver.find_element(By.XPATH, '//*[@id="searchForm"]/section/div/div[3]/a[1]')
btn_click.click()

# 검색되는 시간 기다림
WebDriverWait(driver, 5).until(EC.presence_of_element_located((By.XPATH, '//*[@id="searchForm"]/section/div/div[3]/a[2]')))
time.sleep(5)


# 8. kind 사이트에서 검색된 내용을 엑셀 다운로드 위해 엑셀 버튼 클릭
excel_btn= driver.find_element(By.XPATH, '//*[@id="searchForm"]/section/div/div[3]/a[2]')
excel_btn.click()
time.sleep(3)


# 9. 브라우저 닫기
driver.close() #현재 탭 닫기
driver.quit()  #브라우저 닫기


# 10. pymysql 연결

# pymysql 임포트
import pymysql

# 접속정보
conn = pymysql.connect(host='127.0.0.1', user='root', password='root', db='testDB', charset='utf8')


# 11. 엑셀 파일 읽고 table에 저장
# 엑셀 파일을 메모장으로 열어보면 내용이 html으로 되어 있어 pandas read_html 읽어야 함.
# pd.read_html() 호출하기 위해 pip install html5lib, pip install lxml 설치 필요
# pd.to_sql() 호출하기 위해 piip install psycopg2

import pandas as pd
from sqlalchemy import create_engine, VARCHAR, DATE
from sqlalchemy.engine.url import URL

file = 'C:/Users/10094526/downloads/투자주의종목.xls'

# pd.read_html 읽어오면 리스트 형태로 되어 있고 거기서 [0] 선택하면 해당 내용을 DataFrame 형식으로 넣게 됨.
df = pd.read_html(file, header=0)[0]
df = df.astype(str)
print(df)
print(type(df))
print(len(df))

if len(df):
    del df['번호']
    del df['종목명']
    del df['유형']
    df = df.rename(columns={
        '종목코드': 'code',
        '종목명': 'code_name',
        '공시일': 'post_date',
        '지정일': 'fix_date',
        '유형': 'type',
        '해제일': 'cleared_date'
    })



# df 내용을 pandas to_sql 이용하여 test1_table 테이블에 저장하기

db_url = URL(
    drivername="mysql+pymysql",
    username='root',
    password='root',
    host='127.0.0.1',
    port='3306',
    database='testDB'
)

engine = create_engine(db_url)

df.to_sql('test1_table', con = engine,
    if_exists='append',
    dtype={
        'code': VARCHAR(length=6),
        'post_date': DATE,
        'fix_date': DATE,
        'cleared_date': DATE
    }
)


# 12. 저장된 Table 내용 가져오기

try:
    cur = conn.cursor()
    sql = "SELECT * FROM test1_table"
    cur.execute(sql)
    result = cur.fetchall()
    for row in result:
        data1 = row[0]
        data2 = row[1]
        data3 = row[2]
        data4 = row[3]
        print(f'{data1}, {data2}, {data3}, {data4} ')
finally:
    conn.close()


