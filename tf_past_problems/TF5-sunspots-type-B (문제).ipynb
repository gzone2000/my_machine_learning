{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"TF5-sunspots-type-B (문제)_val_mae_0.10967","provenance":[{"file_id":"1wZ5nk9eGGhMMEZgp6QtF_fwGj3e9p5tx","timestamp":1599024732810}],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"I3_9wrbxeB9J","executionInfo":{"status":"ok","timestamp":1602376218297,"user_tz":-540,"elapsed":107141,"user":{"displayName":"yunwoo oh","photoUrl":"","userId":"01035531558844683999"}},"outputId":"d21155aa-9509-417f-b360-e2e0c66d36a1","colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["# QUESTION\n","#\n","# For this task you will need to train a neural network\n","# to predict sunspot activity using the Sunspots.csv dataset.\n","# Your neural network must  have an MAE\n","# of 0.12 or less on the normalized dataset for top marks.\n","# Code for normalizing the data is provided and should not be changed.\n","# At the bottom of this file, we provide  some testing\n","# code should you want to check your model.\n","\n","# Note: Do not use lambda layers in your model, they are not supported\n","# on the grading infrastructure.\n","\n","# =================================================== #\n","# =================================================== #\n","# ====== 모델링 할 때는 포함, 시험 볼때는 제거 ====== #\n","# 텐서플로우 버전 충돌로 인하여 \n","# 반드시 tensorflow 버전을 2.1.0 버전 설치 후 \n","# 모델작업 진행 해주셔야 합니다.\n","# 시험보실 때는 아래 \n","# !pip install tensorflow==2.1.0 명령어 필요 없습니다\n","# 텐서플로우 2.1.0 버전 재설치 코드\n","#!pip install tensorflow==2.1.0\n","\n","# ====== 모델링 할 때는 포함, 시험 볼때는 제거 ====== #\n","# =================================================== #\n","\n","# =========== 합격 기준 가이드라인 공유 ============= #\n","# val_loss 기준에 맞춰 주시는 것이 훨씬 더 중요 #\n","# val_loss 보다 조금 높아도 상관없음. (언저리까지 OK) #\n","# =================================================== #\n","# 문제명: Category 5 - sunspots type B (NO Lambda)\n","# val_loss: 상관없음\n","# val_mae: 0.1121\n","# =================================================== #\n","# =================================================== #\n","\n","\n","import csv\n","import tensorflow as tf\n","import numpy as np\n","import urllib\n","\n","from tensorflow.keras.layers import Dense, LSTM, Lambda, Conv1D\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.callbacks import ModelCheckpoint\n","from tensorflow.keras.optimizers import SGD\n","from tensorflow.keras.losses import Huber\n","\n","\n","# DO NOT CHANGE THIS CODE\n","def windowed_dataset(series, window_size, batch_size, shuffle_buffer):\n","    series = tf.expand_dims(series, axis=-1)\n","    ds = tf.data.Dataset.from_tensor_slices(series)\n","    ds = ds.window(window_size + 1, shift=1, drop_remainder=True)\n","    ds = ds.flat_map(lambda w: w.batch(window_size + 1))\n","    ds = ds.shuffle(shuffle_buffer)\n","    ds = ds.map(lambda w: (w[:-1], w[1:]))\n","    return ds.batch(batch_size).prefetch(1)\n","\n","\n","def solution_model():\n","    url = 'https://storage.googleapis.com/download.tensorflow.org/data/Sunspots.csv'\n","    urllib.request.urlretrieve(url, 'sunspots.csv')\n","\n","    time_step = []\n","    sunspots = []\n","\n","    with open('sunspots.csv') as csvfile:\n","      reader = csv.reader(csvfile, delimiter=',')\n","      next(reader)\n","      for row in reader:\n","        sunspots.append(float(row[2]))\n","        time_step.append(int(row[0]))\n","\n","    series = np.array(sunspots)\n","    time = np.array(time_step)\n","\n","    # DO NOT CHANGE THIS CODE\n","    # This is the normalization function\n","    min = np.min(series)\n","    max = np.max(series)\n","    series -= min\n","    series /= max\n","    time = np.array(time_step)\n","\n","    # The data should be split into training and validation sets at time step 3000\n","    # DO NOT CHANGE THIS CODE\n","    split_time = 3000\n","\n","    time_train = time[:split_time]\n","    time_valid = time[split_time:]\n","    x_train = series[:split_time]\n","    x_valid = series[split_time:]\n","\n","    # DO NOT CHANGE THIS CODE\n","    window_size = 30\n","    batch_size = 32\n","    shuffle_buffer_size = 1000\n","\n","\n","    train_set = windowed_dataset(x_train, window_size=window_size, batch_size=batch_size, shuffle_buffer=shuffle_buffer_size)\n","    validation_set = windowed_dataset(x_valid, window_size=window_size, batch_size=batch_size, shuffle_buffer=shuffle_buffer_size)\n","\n","\n","    model = tf.keras.models.Sequential([\n","      tf.keras.layers.Conv1D(60, kernel_size=5,\n","                          padding=\"causal\",\n","                          activation=\"relu\",\n","#                          input_shape=[None, 1]),\n","                          input_shape=(30,1)),                          \n","    tf.keras.layers.LSTM(60, return_sequences=True, ),\n","      tf.keras.layers.LSTM(60, return_sequences=True),\n","      tf.keras.layers.Dense(30, activation=\"relu\"),\n","      tf.keras.layers.Dense(10, activation=\"relu\"),                                   \n","\n","      # YOUR CODE HERE. Whatever your first layer is, the input shape will be [None,1] when using the Windowed_dataset above, depending on the layer type chosen\n","      tf.keras.layers.Dense(1)\n","    ])\n","\n","    # YOUR CODE HERE TO COMPILE AND TRAIN THE MODEL\n","    model.summary()\n","    optimizer = SGD(lr=1e-5, momentum=0.9)\n","    loss= Huber()\n","\n","    model.compile(loss=loss,\n","              optimizer=optimizer,\n","              metrics=[\"mae\"])\n","    \n","    checkpoint_path = 'tmp_checkpoint.ckpt'\n","    checkpoint = ModelCheckpoint(checkpoint_path, \n","                             save_weights_only=True, \n","                             save_best_only=True, \n","                             monitor='val_mae',\n","                             verbose=1)\n","    \n","    epochs=100\n","    history = model.fit(train_set, \n","                    validation_data=(validation_set), \n","                    epochs=epochs, \n","                    callbacks=[checkpoint],\n","                   )\n","    \n","    model.load_weights(checkpoint_path)\n","\n","    return model\n","\n","\n","# Note that you'll need to save your model as a .h5 like this.\n","# When you press the Submit and Test button, this .h5 model will be\n","# sent to the testing infrastructure for scoring.\n","\n","# You must use the Submit and Test button to submit your model\n","# at least once in each category before you finally submit your exam.\n","\n","if __name__ == '__main__':\n","    model = solution_model()\n","    model.save(\"TF5-sunspots-type-B.h5\")\n","\n","\n","\n","# THIS CODE IS USED IN THE TESTER FOR FORECASTING. IF YOU WANT TO TEST YOUR MODEL\n","# BEFORE UPLOADING YOU CAN DO IT WITH THIS\n","#def model_forecast(model, series, window_size):\n","#    ds = tf.data.Dataset.from_tensor_slices(series)\n","#    ds = ds.window(window_size, shift=1, drop_remainder=True)\n","#    ds = ds.flat_map(lambda w: w.batch(window_size))\n","#    ds = ds.batch(32).prefetch(1)\n","#    forecast = model.predict(ds)\n","#    return forecast\n","\n","\n","#window_size = # YOUR CODE HERE\n","#rnn_forecast = model_forecast(model, series[..., np.newaxis], window_size)\n","#rnn_forecast = rnn_forecast[split_time - window_size:-1, -1, 0]\n","\n","#result = tf.keras.metrics.mean_absolute_error(x_valid, rnn_forecast).numpy()\n","\n","## To get the maximum score, your model must have an MAE OF .12 or less.\n","## When you Submit and Test your model, the grading infrastructure\n","## converts the MAE of your model to a score from 0 to 5 as follows:\n","\n","#test_val = 100 * result\n","#score = math.ceil(17 - test_val)\n","#if score > 5:\n","#    score = 5\n","\n","#print(score)"],"execution_count":9,"outputs":[{"output_type":"stream","text":["Model: \"sequential_6\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","conv1d_6 (Conv1D)            (None, 30, 60)            360       \n","_________________________________________________________________\n","lstm_12 (LSTM)               (None, 30, 60)            29040     \n","_________________________________________________________________\n","lstm_13 (LSTM)               (None, 30, 60)            29040     \n","_________________________________________________________________\n","dense_18 (Dense)             (None, 30, 30)            1830      \n","_________________________________________________________________\n","dense_19 (Dense)             (None, 30, 10)            310       \n","_________________________________________________________________\n","dense_20 (Dense)             (None, 30, 1)             11        \n","=================================================================\n","Total params: 60,591\n","Trainable params: 60,591\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch 1/100\n","     91/Unknown - 1s 9ms/step - loss: 0.0404 - mae: 0.2193\n","Epoch 00001: val_mae improved from inf to 0.18542, saving model to tmp_checkpoint.ckpt\n","93/93 [==============================] - 2s 17ms/step - loss: 0.0405 - mae: 0.2195 - val_loss: 0.0281 - val_mae: 0.1854\n","Epoch 2/100\n","91/93 [============================>.] - ETA: 0s - loss: 0.0384 - mae: 0.2115\n","Epoch 00002: val_mae improved from 0.18542 to 0.17870, saving model to tmp_checkpoint.ckpt\n","93/93 [==============================] - 1s 10ms/step - loss: 0.0387 - mae: 0.2123 - val_loss: 0.0266 - val_mae: 0.1787\n","Epoch 3/100\n","92/93 [============================>.] - ETA: 0s - loss: 0.0369 - mae: 0.2053\n","Epoch 00003: val_mae improved from 0.17870 to 0.17257, saving model to tmp_checkpoint.ckpt\n","93/93 [==============================] - 1s 10ms/step - loss: 0.0370 - mae: 0.2057 - val_loss: 0.0253 - val_mae: 0.1726\n","Epoch 4/100\n","91/93 [============================>.] - ETA: 0s - loss: 0.0354 - mae: 0.1996\n","Epoch 00004: val_mae improved from 0.17257 to 0.16716, saving model to tmp_checkpoint.ckpt\n","93/93 [==============================] - 1s 10ms/step - loss: 0.0355 - mae: 0.1997 - val_loss: 0.0241 - val_mae: 0.1672\n","Epoch 5/100\n","89/93 [===========================>..] - ETA: 0s - loss: 0.0339 - mae: 0.1935\n","Epoch 00005: val_mae improved from 0.16716 to 0.16245, saving model to tmp_checkpoint.ckpt\n","93/93 [==============================] - 1s 10ms/step - loss: 0.0341 - mae: 0.1943 - val_loss: 0.0230 - val_mae: 0.1625\n","Epoch 6/100\n","93/93 [==============================] - ETA: 0s - loss: 0.0328 - mae: 0.1894\n","Epoch 00006: val_mae improved from 0.16245 to 0.15832, saving model to tmp_checkpoint.ckpt\n","93/93 [==============================] - 1s 10ms/step - loss: 0.0328 - mae: 0.1894 - val_loss: 0.0220 - val_mae: 0.1583\n","Epoch 7/100\n","91/93 [============================>.] - ETA: 0s - loss: 0.0318 - mae: 0.1855\n","Epoch 00007: val_mae improved from 0.15832 to 0.15459, saving model to tmp_checkpoint.ckpt\n","93/93 [==============================] - 1s 10ms/step - loss: 0.0317 - mae: 0.1852 - val_loss: 0.0211 - val_mae: 0.1546\n","Epoch 8/100\n","92/93 [============================>.] - ETA: 0s - loss: 0.0307 - mae: 0.1811\n","Epoch 00008: val_mae improved from 0.15459 to 0.15121, saving model to tmp_checkpoint.ckpt\n","93/93 [==============================] - 1s 10ms/step - loss: 0.0307 - mae: 0.1813 - val_loss: 0.0204 - val_mae: 0.1512\n","Epoch 9/100\n","93/93 [==============================] - ETA: 0s - loss: 0.0298 - mae: 0.1778\n","Epoch 00009: val_mae improved from 0.15121 to 0.14802, saving model to tmp_checkpoint.ckpt\n","93/93 [==============================] - 1s 10ms/step - loss: 0.0298 - mae: 0.1778 - val_loss: 0.0197 - val_mae: 0.1480\n","Epoch 10/100\n","88/93 [===========================>..] - ETA: 0s - loss: 0.0287 - mae: 0.1739\n","Epoch 00010: val_mae improved from 0.14802 to 0.14510, saving model to tmp_checkpoint.ckpt\n","93/93 [==============================] - 1s 10ms/step - loss: 0.0289 - mae: 0.1747 - val_loss: 0.0190 - val_mae: 0.1451\n","Epoch 11/100\n","91/93 [============================>.] - ETA: 0s - loss: 0.0282 - mae: 0.1721\n","Epoch 00011: val_mae improved from 0.14510 to 0.14246, saving model to tmp_checkpoint.ckpt\n","93/93 [==============================] - 1s 10ms/step - loss: 0.0281 - mae: 0.1717 - val_loss: 0.0184 - val_mae: 0.1425\n","Epoch 12/100\n","88/93 [===========================>..] - ETA: 0s - loss: 0.0272 - mae: 0.1683\n","Epoch 00012: val_mae improved from 0.14246 to 0.14005, saving model to tmp_checkpoint.ckpt\n","93/93 [==============================] - 1s 10ms/step - loss: 0.0274 - mae: 0.1690 - val_loss: 0.0179 - val_mae: 0.1401\n","Epoch 13/100\n","91/93 [============================>.] - ETA: 0s - loss: 0.0266 - mae: 0.1662\n","Epoch 00013: val_mae improved from 0.14005 to 0.13788, saving model to tmp_checkpoint.ckpt\n","93/93 [==============================] - 1s 10ms/step - loss: 0.0267 - mae: 0.1666 - val_loss: 0.0173 - val_mae: 0.1379\n","Epoch 14/100\n","91/93 [============================>.] - ETA: 0s - loss: 0.0261 - mae: 0.1644\n","Epoch 00014: val_mae improved from 0.13788 to 0.13588, saving model to tmp_checkpoint.ckpt\n","93/93 [==============================] - 1s 10ms/step - loss: 0.0261 - mae: 0.1643 - val_loss: 0.0168 - val_mae: 0.1359\n","Epoch 15/100\n","91/93 [============================>.] - ETA: 0s - loss: 0.0254 - mae: 0.1619\n","Epoch 00015: val_mae improved from 0.13588 to 0.13402, saving model to tmp_checkpoint.ckpt\n","93/93 [==============================] - 1s 10ms/step - loss: 0.0254 - mae: 0.1621 - val_loss: 0.0164 - val_mae: 0.1340\n","Epoch 16/100\n","91/93 [============================>.] - ETA: 0s - loss: 0.0247 - mae: 0.1595\n","Epoch 00016: val_mae improved from 0.13402 to 0.13234, saving model to tmp_checkpoint.ckpt\n","93/93 [==============================] - 1s 10ms/step - loss: 0.0249 - mae: 0.1601 - val_loss: 0.0159 - val_mae: 0.1323\n","Epoch 17/100\n","90/93 [============================>.] - ETA: 0s - loss: 0.0242 - mae: 0.1580\n","Epoch 00017: val_mae improved from 0.13234 to 0.13078, saving model to tmp_checkpoint.ckpt\n","93/93 [==============================] - 1s 10ms/step - loss: 0.0243 - mae: 0.1583 - val_loss: 0.0155 - val_mae: 0.1308\n","Epoch 18/100\n","90/93 [============================>.] - ETA: 0s - loss: 0.0235 - mae: 0.1554\n","Epoch 00018: val_mae improved from 0.13078 to 0.12934, saving model to tmp_checkpoint.ckpt\n","93/93 [==============================] - 1s 10ms/step - loss: 0.0238 - mae: 0.1565 - val_loss: 0.0152 - val_mae: 0.1293\n","Epoch 19/100\n","91/93 [============================>.] - ETA: 0s - loss: 0.0233 - mae: 0.1547\n","Epoch 00019: val_mae improved from 0.12934 to 0.12797, saving model to tmp_checkpoint.ckpt\n","93/93 [==============================] - 1s 10ms/step - loss: 0.0233 - mae: 0.1548 - val_loss: 0.0148 - val_mae: 0.1280\n","Epoch 20/100\n","93/93 [==============================] - ETA: 0s - loss: 0.0229 - mae: 0.1533\n","Epoch 00020: val_mae improved from 0.12797 to 0.12668, saving model to tmp_checkpoint.ckpt\n","93/93 [==============================] - 1s 10ms/step - loss: 0.0229 - mae: 0.1533 - val_loss: 0.0145 - val_mae: 0.1267\n","Epoch 21/100\n","93/93 [==============================] - ETA: 0s - loss: 0.0224 - mae: 0.1518\n","Epoch 00021: val_mae improved from 0.12668 to 0.12553, saving model to tmp_checkpoint.ckpt\n","93/93 [==============================] - 1s 10ms/step - loss: 0.0224 - mae: 0.1518 - val_loss: 0.0141 - val_mae: 0.1255\n","Epoch 22/100\n","92/93 [============================>.] - ETA: 0s - loss: 0.0219 - mae: 0.1503\n","Epoch 00022: val_mae improved from 0.12553 to 0.12442, saving model to tmp_checkpoint.ckpt\n","93/93 [==============================] - 1s 10ms/step - loss: 0.0220 - mae: 0.1504 - val_loss: 0.0138 - val_mae: 0.1244\n","Epoch 23/100\n","89/93 [===========================>..] - ETA: 0s - loss: 0.0216 - mae: 0.1492\n","Epoch 00023: val_mae improved from 0.12442 to 0.12334, saving model to tmp_checkpoint.ckpt\n","93/93 [==============================] - 1s 10ms/step - loss: 0.0216 - mae: 0.1492 - val_loss: 0.0135 - val_mae: 0.1233\n","Epoch 24/100\n","92/93 [============================>.] - ETA: 0s - loss: 0.0212 - mae: 0.1479\n","Epoch 00024: val_mae improved from 0.12334 to 0.12238, saving model to tmp_checkpoint.ckpt\n","93/93 [==============================] - 1s 10ms/step - loss: 0.0212 - mae: 0.1480 - val_loss: 0.0133 - val_mae: 0.1224\n","Epoch 25/100\n","88/93 [===========================>..] - ETA: 0s - loss: 0.0208 - mae: 0.1466\n","Epoch 00025: val_mae improved from 0.12238 to 0.12150, saving model to tmp_checkpoint.ckpt\n","93/93 [==============================] - 1s 11ms/step - loss: 0.0209 - mae: 0.1468 - val_loss: 0.0130 - val_mae: 0.1215\n","Epoch 26/100\n","91/93 [============================>.] - ETA: 0s - loss: 0.0204 - mae: 0.1453\n","Epoch 00026: val_mae improved from 0.12150 to 0.12069, saving model to tmp_checkpoint.ckpt\n","93/93 [==============================] - 1s 10ms/step - loss: 0.0205 - mae: 0.1458 - val_loss: 0.0128 - val_mae: 0.1207\n","Epoch 27/100\n","92/93 [============================>.] - ETA: 0s - loss: 0.0201 - mae: 0.1444\n","Epoch 00027: val_mae improved from 0.12069 to 0.11992, saving model to tmp_checkpoint.ckpt\n","93/93 [==============================] - 1s 11ms/step - loss: 0.0202 - mae: 0.1448 - val_loss: 0.0126 - val_mae: 0.1199\n","Epoch 28/100\n","88/93 [===========================>..] - ETA: 0s - loss: 0.0197 - mae: 0.1427\n","Epoch 00028: val_mae improved from 0.11992 to 0.11920, saving model to tmp_checkpoint.ckpt\n","93/93 [==============================] - 1s 10ms/step - loss: 0.0199 - mae: 0.1439 - val_loss: 0.0124 - val_mae: 0.1192\n","Epoch 29/100\n","90/93 [============================>.] - ETA: 0s - loss: 0.0195 - mae: 0.1424\n","Epoch 00029: val_mae improved from 0.11920 to 0.11850, saving model to tmp_checkpoint.ckpt\n","93/93 [==============================] - 1s 11ms/step - loss: 0.0196 - mae: 0.1430 - val_loss: 0.0122 - val_mae: 0.1185\n","Epoch 30/100\n","92/93 [============================>.] - ETA: 0s - loss: 0.0193 - mae: 0.1420\n","Epoch 00030: val_mae improved from 0.11850 to 0.11783, saving model to tmp_checkpoint.ckpt\n","93/93 [==============================] - 1s 10ms/step - loss: 0.0193 - mae: 0.1421 - val_loss: 0.0120 - val_mae: 0.1178\n","Epoch 31/100\n","92/93 [============================>.] - ETA: 0s - loss: 0.0191 - mae: 0.1416\n","Epoch 00031: val_mae improved from 0.11783 to 0.11719, saving model to tmp_checkpoint.ckpt\n","93/93 [==============================] - 1s 11ms/step - loss: 0.0191 - mae: 0.1414 - val_loss: 0.0118 - val_mae: 0.1172\n","Epoch 32/100\n","92/93 [============================>.] - ETA: 0s - loss: 0.0188 - mae: 0.1405\n","Epoch 00032: val_mae improved from 0.11719 to 0.11658, saving model to tmp_checkpoint.ckpt\n","93/93 [==============================] - 1s 10ms/step - loss: 0.0188 - mae: 0.1406 - val_loss: 0.0116 - val_mae: 0.1166\n","Epoch 33/100\n","93/93 [==============================] - ETA: 0s - loss: 0.0186 - mae: 0.1400\n","Epoch 00033: val_mae improved from 0.11658 to 0.11600, saving model to tmp_checkpoint.ckpt\n","93/93 [==============================] - 1s 11ms/step - loss: 0.0186 - mae: 0.1400 - val_loss: 0.0115 - val_mae: 0.1160\n","Epoch 34/100\n","90/93 [============================>.] - ETA: 0s - loss: 0.0183 - mae: 0.1389\n","Epoch 00034: val_mae improved from 0.11600 to 0.11546, saving model to tmp_checkpoint.ckpt\n","93/93 [==============================] - 1s 11ms/step - loss: 0.0184 - mae: 0.1394 - val_loss: 0.0113 - val_mae: 0.1155\n","Epoch 35/100\n","90/93 [============================>.] - ETA: 0s - loss: 0.0180 - mae: 0.1381\n","Epoch 00035: val_mae improved from 0.11546 to 0.11494, saving model to tmp_checkpoint.ckpt\n","93/93 [==============================] - 1s 10ms/step - loss: 0.0181 - mae: 0.1388 - val_loss: 0.0112 - val_mae: 0.1149\n","Epoch 36/100\n","93/93 [==============================] - ETA: 0s - loss: 0.0179 - mae: 0.1382\n","Epoch 00036: val_mae improved from 0.11494 to 0.11444, saving model to tmp_checkpoint.ckpt\n","93/93 [==============================] - 1s 10ms/step - loss: 0.0179 - mae: 0.1382 - val_loss: 0.0110 - val_mae: 0.1144\n","Epoch 37/100\n","88/93 [===========================>..] - ETA: 0s - loss: 0.0175 - mae: 0.1368\n","Epoch 00037: val_mae improved from 0.11444 to 0.11397, saving model to tmp_checkpoint.ckpt\n","93/93 [==============================] - 1s 10ms/step - loss: 0.0177 - mae: 0.1377 - val_loss: 0.0109 - val_mae: 0.1140\n","Epoch 38/100\n","90/93 [============================>.] - ETA: 0s - loss: 0.0174 - mae: 0.1369\n","Epoch 00038: val_mae improved from 0.11397 to 0.11352, saving model to tmp_checkpoint.ckpt\n","93/93 [==============================] - 1s 10ms/step - loss: 0.0176 - mae: 0.1372 - val_loss: 0.0108 - val_mae: 0.1135\n","Epoch 39/100\n","91/93 [============================>.] - ETA: 0s - loss: 0.0174 - mae: 0.1369\n","Epoch 00039: val_mae improved from 0.11352 to 0.11312, saving model to tmp_checkpoint.ckpt\n","93/93 [==============================] - 1s 10ms/step - loss: 0.0174 - mae: 0.1368 - val_loss: 0.0107 - val_mae: 0.1131\n","Epoch 40/100\n","89/93 [===========================>..] - ETA: 0s - loss: 0.0168 - mae: 0.1348\n","Epoch 00040: val_mae improved from 0.11312 to 0.11276, saving model to tmp_checkpoint.ckpt\n","93/93 [==============================] - 1s 10ms/step - loss: 0.0172 - mae: 0.1363 - val_loss: 0.0106 - val_mae: 0.1128\n","Epoch 41/100\n","88/93 [===========================>..] - ETA: 0s - loss: 0.0171 - mae: 0.1362\n","Epoch 00041: val_mae improved from 0.11276 to 0.11240, saving model to tmp_checkpoint.ckpt\n","93/93 [==============================] - 1s 10ms/step - loss: 0.0171 - mae: 0.1360 - val_loss: 0.0105 - val_mae: 0.1124\n","Epoch 42/100\n","90/93 [============================>.] - ETA: 0s - loss: 0.0168 - mae: 0.1350\n","Epoch 00042: val_mae improved from 0.11240 to 0.11207, saving model to tmp_checkpoint.ckpt\n","93/93 [==============================] - 1s 10ms/step - loss: 0.0169 - mae: 0.1356 - val_loss: 0.0104 - val_mae: 0.1121\n","Epoch 43/100\n","89/93 [===========================>..] - ETA: 0s - loss: 0.0167 - mae: 0.1350\n","Epoch 00043: val_mae improved from 0.11207 to 0.11176, saving model to tmp_checkpoint.ckpt\n","93/93 [==============================] - 1s 10ms/step - loss: 0.0167 - mae: 0.1352 - val_loss: 0.0103 - val_mae: 0.1118\n","Epoch 44/100\n","92/93 [============================>.] - ETA: 0s - loss: 0.0166 - mae: 0.1348\n","Epoch 00044: val_mae improved from 0.11176 to 0.11147, saving model to tmp_checkpoint.ckpt\n","93/93 [==============================] - 1s 10ms/step - loss: 0.0166 - mae: 0.1349 - val_loss: 0.0102 - val_mae: 0.1115\n","Epoch 45/100\n","92/93 [============================>.] - ETA: 0s - loss: 0.0165 - mae: 0.1346\n","Epoch 00045: val_mae improved from 0.11147 to 0.11122, saving model to tmp_checkpoint.ckpt\n","93/93 [==============================] - 1s 10ms/step - loss: 0.0165 - mae: 0.1346 - val_loss: 0.0101 - val_mae: 0.1112\n","Epoch 46/100\n","91/93 [============================>.] - ETA: 0s - loss: 0.0163 - mae: 0.1339\n","Epoch 00046: val_mae improved from 0.11122 to 0.11099, saving model to tmp_checkpoint.ckpt\n","93/93 [==============================] - 1s 10ms/step - loss: 0.0163 - mae: 0.1343 - val_loss: 0.0101 - val_mae: 0.1110\n","Epoch 47/100\n","90/93 [============================>.] - ETA: 0s - loss: 0.0161 - mae: 0.1335\n","Epoch 00047: val_mae improved from 0.11099 to 0.11077, saving model to tmp_checkpoint.ckpt\n","93/93 [==============================] - 1s 10ms/step - loss: 0.0162 - mae: 0.1340 - val_loss: 0.0100 - val_mae: 0.1108\n","Epoch 48/100\n","92/93 [============================>.] - ETA: 0s - loss: 0.0161 - mae: 0.1337\n","Epoch 00048: val_mae improved from 0.11077 to 0.11057, saving model to tmp_checkpoint.ckpt\n","93/93 [==============================] - 1s 10ms/step - loss: 0.0161 - mae: 0.1338 - val_loss: 0.0099 - val_mae: 0.1106\n","Epoch 49/100\n","87/93 [===========================>..] - ETA: 0s - loss: 0.0159 - mae: 0.1330\n","Epoch 00049: val_mae improved from 0.11057 to 0.11039, saving model to tmp_checkpoint.ckpt\n","93/93 [==============================] - 1s 10ms/step - loss: 0.0160 - mae: 0.1335 - val_loss: 0.0099 - val_mae: 0.1104\n","Epoch 50/100\n","93/93 [==============================] - ETA: 0s - loss: 0.0159 - mae: 0.1333\n","Epoch 00050: val_mae improved from 0.11039 to 0.11022, saving model to tmp_checkpoint.ckpt\n","93/93 [==============================] - 1s 10ms/step - loss: 0.0159 - mae: 0.1333 - val_loss: 0.0098 - val_mae: 0.1102\n","Epoch 51/100\n","91/93 [============================>.] - ETA: 0s - loss: 0.0158 - mae: 0.1332\n","Epoch 00051: val_mae improved from 0.11022 to 0.11008, saving model to tmp_checkpoint.ckpt\n","93/93 [==============================] - 1s 10ms/step - loss: 0.0158 - mae: 0.1331 - val_loss: 0.0098 - val_mae: 0.1101\n","Epoch 52/100\n","88/93 [===========================>..] - ETA: 0s - loss: 0.0156 - mae: 0.1325\n","Epoch 00052: val_mae improved from 0.11008 to 0.10994, saving model to tmp_checkpoint.ckpt\n","93/93 [==============================] - 1s 10ms/step - loss: 0.0157 - mae: 0.1329 - val_loss: 0.0097 - val_mae: 0.1099\n","Epoch 53/100\n","88/93 [===========================>..] - ETA: 0s - loss: 0.0156 - mae: 0.1326\n","Epoch 00053: val_mae improved from 0.10994 to 0.10983, saving model to tmp_checkpoint.ckpt\n","93/93 [==============================] - 1s 10ms/step - loss: 0.0156 - mae: 0.1327 - val_loss: 0.0097 - val_mae: 0.1098\n","Epoch 54/100\n","93/93 [==============================] - ETA: 0s - loss: 0.0155 - mae: 0.1325\n","Epoch 00054: val_mae improved from 0.10983 to 0.10974, saving model to tmp_checkpoint.ckpt\n","93/93 [==============================] - 1s 10ms/step - loss: 0.0155 - mae: 0.1325 - val_loss: 0.0096 - val_mae: 0.1097\n","Epoch 55/100\n","90/93 [============================>.] - ETA: 0s - loss: 0.0154 - mae: 0.1324\n","Epoch 00055: val_mae improved from 0.10974 to 0.10967, saving model to tmp_checkpoint.ckpt\n","93/93 [==============================] - 1s 10ms/step - loss: 0.0154 - mae: 0.1324 - val_loss: 0.0096 - val_mae: 0.1097\n","Epoch 56/100\n","90/93 [============================>.] - ETA: 0s - loss: 0.0152 - mae: 0.1317\n","Epoch 00056: val_mae improved from 0.10967 to 0.10960, saving model to tmp_checkpoint.ckpt\n","93/93 [==============================] - 1s 10ms/step - loss: 0.0153 - mae: 0.1322 - val_loss: 0.0095 - val_mae: 0.1096\n","Epoch 57/100\n","89/93 [===========================>..] - ETA: 0s - loss: 0.0151 - mae: 0.1313\n","Epoch 00057: val_mae improved from 0.10960 to 0.10956, saving model to tmp_checkpoint.ckpt\n","93/93 [==============================] - 1s 10ms/step - loss: 0.0153 - mae: 0.1321 - val_loss: 0.0095 - val_mae: 0.1096\n","Epoch 58/100\n","92/93 [============================>.] - ETA: 0s - loss: 0.0151 - mae: 0.1317\n","Epoch 00058: val_mae improved from 0.10956 to 0.10952, saving model to tmp_checkpoint.ckpt\n","93/93 [==============================] - 1s 10ms/step - loss: 0.0152 - mae: 0.1319 - val_loss: 0.0095 - val_mae: 0.1095\n","Epoch 59/100\n","89/93 [===========================>..] - ETA: 0s - loss: 0.0150 - mae: 0.1312\n","Epoch 00059: val_mae improved from 0.10952 to 0.10950, saving model to tmp_checkpoint.ckpt\n","93/93 [==============================] - 1s 10ms/step - loss: 0.0151 - mae: 0.1318 - val_loss: 0.0094 - val_mae: 0.1095\n","Epoch 60/100\n","88/93 [===========================>..] - ETA: 0s - loss: 0.0149 - mae: 0.1309\n","Epoch 00060: val_mae improved from 0.10950 to 0.10948, saving model to tmp_checkpoint.ckpt\n","93/93 [==============================] - 1s 10ms/step - loss: 0.0150 - mae: 0.1317 - val_loss: 0.0094 - val_mae: 0.1095\n","Epoch 61/100\n","91/93 [============================>.] - ETA: 0s - loss: 0.0149 - mae: 0.1311\n","Epoch 00061: val_mae improved from 0.10948 to 0.10946, saving model to tmp_checkpoint.ckpt\n","93/93 [==============================] - 1s 10ms/step - loss: 0.0150 - mae: 0.1315 - val_loss: 0.0094 - val_mae: 0.1095\n","Epoch 62/100\n","89/93 [===========================>..] - ETA: 0s - loss: 0.0149 - mae: 0.1312\n","Epoch 00062: val_mae improved from 0.10946 to 0.10945, saving model to tmp_checkpoint.ckpt\n","93/93 [==============================] - 1s 10ms/step - loss: 0.0149 - mae: 0.1314 - val_loss: 0.0093 - val_mae: 0.1094\n","Epoch 63/100\n","87/93 [===========================>..] - ETA: 0s - loss: 0.0147 - mae: 0.1306\n","Epoch 00063: val_mae improved from 0.10945 to 0.10944, saving model to tmp_checkpoint.ckpt\n","93/93 [==============================] - 1s 10ms/step - loss: 0.0149 - mae: 0.1313 - val_loss: 0.0093 - val_mae: 0.1094\n","Epoch 64/100\n","90/93 [============================>.] - ETA: 0s - loss: 0.0147 - mae: 0.1308\n","Epoch 00064: val_mae improved from 0.10944 to 0.10943, saving model to tmp_checkpoint.ckpt\n","93/93 [==============================] - 1s 10ms/step - loss: 0.0148 - mae: 0.1313 - val_loss: 0.0093 - val_mae: 0.1094\n","Epoch 65/100\n","91/93 [============================>.] - ETA: 0s - loss: 0.0147 - mae: 0.1310\n","Epoch 00065: val_mae improved from 0.10943 to 0.10942, saving model to tmp_checkpoint.ckpt\n","93/93 [==============================] - 1s 10ms/step - loss: 0.0147 - mae: 0.1312 - val_loss: 0.0093 - val_mae: 0.1094\n","Epoch 66/100\n","90/93 [============================>.] - ETA: 0s - loss: 0.0146 - mae: 0.1309\n","Epoch 00066: val_mae did not improve from 0.10942\n","93/93 [==============================] - 1s 10ms/step - loss: 0.0147 - mae: 0.1311 - val_loss: 0.0092 - val_mae: 0.1094\n","Epoch 67/100\n","93/93 [==============================] - ETA: 0s - loss: 0.0146 - mae: 0.1310\n","Epoch 00067: val_mae did not improve from 0.10942\n","93/93 [==============================] - 1s 10ms/step - loss: 0.0146 - mae: 0.1310 - val_loss: 0.0092 - val_mae: 0.1094\n","Epoch 68/100\n","91/93 [============================>.] - ETA: 0s - loss: 0.0146 - mae: 0.1310\n","Epoch 00068: val_mae did not improve from 0.10942\n","93/93 [==============================] - 1s 10ms/step - loss: 0.0146 - mae: 0.1309 - val_loss: 0.0092 - val_mae: 0.1095\n","Epoch 69/100\n","88/93 [===========================>..] - ETA: 0s - loss: 0.0144 - mae: 0.1301\n","Epoch 00069: val_mae did not improve from 0.10942\n","93/93 [==============================] - 1s 10ms/step - loss: 0.0145 - mae: 0.1309 - val_loss: 0.0092 - val_mae: 0.1095\n","Epoch 70/100\n","89/93 [===========================>..] - ETA: 0s - loss: 0.0145 - mae: 0.1306\n","Epoch 00070: val_mae did not improve from 0.10942\n","93/93 [==============================] - 1s 10ms/step - loss: 0.0145 - mae: 0.1308 - val_loss: 0.0092 - val_mae: 0.1095\n","Epoch 71/100\n","88/93 [===========================>..] - ETA: 0s - loss: 0.0145 - mae: 0.1307\n","Epoch 00071: val_mae did not improve from 0.10942\n","93/93 [==============================] - 1s 10ms/step - loss: 0.0144 - mae: 0.1307 - val_loss: 0.0092 - val_mae: 0.1095\n","Epoch 72/100\n","92/93 [============================>.] - ETA: 0s - loss: 0.0144 - mae: 0.1307\n","Epoch 00072: val_mae did not improve from 0.10942\n","93/93 [==============================] - 1s 10ms/step - loss: 0.0144 - mae: 0.1307 - val_loss: 0.0091 - val_mae: 0.1096\n","Epoch 73/100\n","93/93 [==============================] - ETA: 0s - loss: 0.0144 - mae: 0.1306\n","Epoch 00073: val_mae did not improve from 0.10942\n","93/93 [==============================] - 1s 10ms/step - loss: 0.0144 - mae: 0.1306 - val_loss: 0.0091 - val_mae: 0.1096\n","Epoch 74/100\n","93/93 [==============================] - ETA: 0s - loss: 0.0143 - mae: 0.1306\n","Epoch 00074: val_mae did not improve from 0.10942\n","93/93 [==============================] - 1s 10ms/step - loss: 0.0143 - mae: 0.1306 - val_loss: 0.0091 - val_mae: 0.1096\n","Epoch 75/100\n","90/93 [============================>.] - ETA: 0s - loss: 0.0142 - mae: 0.1302\n","Epoch 00075: val_mae did not improve from 0.10942\n","93/93 [==============================] - 1s 10ms/step - loss: 0.0143 - mae: 0.1305 - val_loss: 0.0091 - val_mae: 0.1097\n","Epoch 76/100\n","88/93 [===========================>..] - ETA: 0s - loss: 0.0142 - mae: 0.1302\n","Epoch 00076: val_mae did not improve from 0.10942\n","93/93 [==============================] - 1s 10ms/step - loss: 0.0143 - mae: 0.1305 - val_loss: 0.0091 - val_mae: 0.1097\n","Epoch 77/100\n","92/93 [============================>.] - ETA: 0s - loss: 0.0142 - mae: 0.1303\n","Epoch 00077: val_mae did not improve from 0.10942\n","93/93 [==============================] - 1s 10ms/step - loss: 0.0142 - mae: 0.1305 - val_loss: 0.0091 - val_mae: 0.1098\n","Epoch 78/100\n","89/93 [===========================>..] - ETA: 0s - loss: 0.0141 - mae: 0.1302\n","Epoch 00078: val_mae did not improve from 0.10942\n","93/93 [==============================] - 1s 10ms/step - loss: 0.0142 - mae: 0.1304 - val_loss: 0.0091 - val_mae: 0.1098\n","Epoch 79/100\n","91/93 [============================>.] - ETA: 0s - loss: 0.0141 - mae: 0.1302\n","Epoch 00079: val_mae did not improve from 0.10942\n","93/93 [==============================] - 1s 10ms/step - loss: 0.0141 - mae: 0.1304 - val_loss: 0.0091 - val_mae: 0.1098\n","Epoch 80/100\n","89/93 [===========================>..] - ETA: 0s - loss: 0.0141 - mae: 0.1304\n","Epoch 00080: val_mae did not improve from 0.10942\n","93/93 [==============================] - 1s 10ms/step - loss: 0.0141 - mae: 0.1304 - val_loss: 0.0091 - val_mae: 0.1099\n","Epoch 81/100\n","88/93 [===========================>..] - ETA: 0s - loss: 0.0139 - mae: 0.1295\n","Epoch 00081: val_mae did not improve from 0.10942\n","93/93 [==============================] - 1s 10ms/step - loss: 0.0141 - mae: 0.1303 - val_loss: 0.0091 - val_mae: 0.1099\n","Epoch 82/100\n","88/93 [===========================>..] - ETA: 0s - loss: 0.0139 - mae: 0.1295\n","Epoch 00082: val_mae did not improve from 0.10942\n","93/93 [==============================] - 1s 10ms/step - loss: 0.0141 - mae: 0.1303 - val_loss: 0.0091 - val_mae: 0.1100\n","Epoch 83/100\n","88/93 [===========================>..] - ETA: 0s - loss: 0.0140 - mae: 0.1301\n","Epoch 00083: val_mae did not improve from 0.10942\n","93/93 [==============================] - 1s 10ms/step - loss: 0.0140 - mae: 0.1303 - val_loss: 0.0090 - val_mae: 0.1100\n","Epoch 84/100\n","93/93 [==============================] - ETA: 0s - loss: 0.0140 - mae: 0.1303\n","Epoch 00084: val_mae did not improve from 0.10942\n","93/93 [==============================] - 1s 10ms/step - loss: 0.0140 - mae: 0.1303 - val_loss: 0.0090 - val_mae: 0.1101\n","Epoch 85/100\n","93/93 [==============================] - ETA: 0s - loss: 0.0140 - mae: 0.1302\n","Epoch 00085: val_mae did not improve from 0.10942\n","93/93 [==============================] - 1s 10ms/step - loss: 0.0140 - mae: 0.1302 - val_loss: 0.0090 - val_mae: 0.1101\n","Epoch 86/100\n","91/93 [============================>.] - ETA: 0s - loss: 0.0140 - mae: 0.1303\n","Epoch 00086: val_mae did not improve from 0.10942\n","93/93 [==============================] - 1s 10ms/step - loss: 0.0140 - mae: 0.1302 - val_loss: 0.0090 - val_mae: 0.1102\n","Epoch 87/100\n","88/93 [===========================>..] - ETA: 0s - loss: 0.0138 - mae: 0.1298\n","Epoch 00087: val_mae did not improve from 0.10942\n","93/93 [==============================] - 1s 10ms/step - loss: 0.0139 - mae: 0.1302 - val_loss: 0.0090 - val_mae: 0.1102\n","Epoch 88/100\n","90/93 [============================>.] - ETA: 0s - loss: 0.0139 - mae: 0.1300\n","Epoch 00088: val_mae did not improve from 0.10942\n","93/93 [==============================] - 1s 10ms/step - loss: 0.0139 - mae: 0.1302 - val_loss: 0.0090 - val_mae: 0.1103\n","Epoch 89/100\n","89/93 [===========================>..] - ETA: 0s - loss: 0.0137 - mae: 0.1295\n","Epoch 00089: val_mae did not improve from 0.10942\n","93/93 [==============================] - 1s 10ms/step - loss: 0.0139 - mae: 0.1302 - val_loss: 0.0090 - val_mae: 0.1103\n","Epoch 90/100\n","89/93 [===========================>..] - ETA: 0s - loss: 0.0138 - mae: 0.1298\n","Epoch 00090: val_mae did not improve from 0.10942\n","93/93 [==============================] - 1s 10ms/step - loss: 0.0139 - mae: 0.1302 - val_loss: 0.0090 - val_mae: 0.1104\n","Epoch 91/100\n","88/93 [===========================>..] - ETA: 0s - loss: 0.0137 - mae: 0.1296\n","Epoch 00091: val_mae did not improve from 0.10942\n","93/93 [==============================] - 1s 10ms/step - loss: 0.0138 - mae: 0.1301 - val_loss: 0.0090 - val_mae: 0.1104\n","Epoch 92/100\n","91/93 [============================>.] - ETA: 0s - loss: 0.0138 - mae: 0.1299\n","Epoch 00092: val_mae did not improve from 0.10942\n","93/93 [==============================] - 1s 10ms/step - loss: 0.0138 - mae: 0.1301 - val_loss: 0.0090 - val_mae: 0.1105\n","Epoch 93/100\n","91/93 [============================>.] - ETA: 0s - loss: 0.0137 - mae: 0.1299\n","Epoch 00093: val_mae did not improve from 0.10942\n","93/93 [==============================] - 1s 10ms/step - loss: 0.0138 - mae: 0.1301 - val_loss: 0.0090 - val_mae: 0.1105\n","Epoch 94/100\n","87/93 [===========================>..] - ETA: 0s - loss: 0.0137 - mae: 0.1297\n","Epoch 00094: val_mae did not improve from 0.10942\n","93/93 [==============================] - 1s 10ms/step - loss: 0.0138 - mae: 0.1301 - val_loss: 0.0090 - val_mae: 0.1106\n","Epoch 95/100\n","89/93 [===========================>..] - ETA: 0s - loss: 0.0136 - mae: 0.1294\n","Epoch 00095: val_mae did not improve from 0.10942\n","93/93 [==============================] - 1s 10ms/step - loss: 0.0138 - mae: 0.1301 - val_loss: 0.0090 - val_mae: 0.1106\n","Epoch 96/100\n","88/93 [===========================>..] - ETA: 0s - loss: 0.0137 - mae: 0.1299\n","Epoch 00096: val_mae did not improve from 0.10942\n","93/93 [==============================] - 1s 10ms/step - loss: 0.0137 - mae: 0.1301 - val_loss: 0.0090 - val_mae: 0.1107\n","Epoch 97/100\n","90/93 [============================>.] - ETA: 0s - loss: 0.0137 - mae: 0.1299\n","Epoch 00097: val_mae did not improve from 0.10942\n","93/93 [==============================] - 1s 10ms/step - loss: 0.0137 - mae: 0.1301 - val_loss: 0.0090 - val_mae: 0.1107\n","Epoch 98/100\n","90/93 [============================>.] - ETA: 0s - loss: 0.0136 - mae: 0.1298\n","Epoch 00098: val_mae did not improve from 0.10942\n","93/93 [==============================] - 1s 10ms/step - loss: 0.0137 - mae: 0.1301 - val_loss: 0.0090 - val_mae: 0.1108\n","Epoch 99/100\n","90/93 [============================>.] - ETA: 0s - loss: 0.0136 - mae: 0.1298\n","Epoch 00099: val_mae did not improve from 0.10942\n","93/93 [==============================] - 1s 10ms/step - loss: 0.0137 - mae: 0.1301 - val_loss: 0.0090 - val_mae: 0.1108\n","Epoch 100/100\n","88/93 [===========================>..] - ETA: 0s - loss: 0.0136 - mae: 0.1295\n","Epoch 00100: val_mae did not improve from 0.10942\n","93/93 [==============================] - 1s 10ms/step - loss: 0.0137 - mae: 0.1301 - val_loss: 0.0090 - val_mae: 0.1109\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"PGSk0Yo0W6N5"},"source":[""],"execution_count":null,"outputs":[]}]}