{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Copy of 5.TF3-rps (문제)","provenance":[{"file_id":"1DMvx22cbYvR24WKKSu-BDmZRKIfk_CDE","timestamp":1598949788211}],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"cg-hP0itZxmX","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"error","timestamp":1598971888817,"user_tz":-540,"elapsed":423268,"user":{"displayName":"yunwoo oh","photoUrl":"","userId":"01035531558844683999"}},"outputId":"fd320905-5cbf-4539-999a-7d383a31522d"},"source":["# ======================================================================\n","# There are 5 questions in this test with increasing difficulty from 1-5\n","# Please note that the weight of the grade for the question is relative\n","# to its difficulty. So your Category 1 question will score much less\n","# than your Category 5 question.\n","# ======================================================================\n","#\n","# Computer Vision with CNNs\n","#\n","# For this task you will build a classifier for Rock-Paper-Scissors \n","# based on the rps dataset.\n","#\n","# IMPORTANT: Your final layer should be as shown, do not change the\n","# provided code, or the tests may fail\n","#\n","# IMPORTANT: Images will be tested as 150x150 with 3 bytes of color depth\n","# So ensure that your input layer is designed accordingly, or the tests\n","# may fail. \n","#\n","# NOTE THAT THIS IS UNLABELLED DATA. \n","# You can use the ImageDataGenerator to automatically label it\n","# and we have provided some starter code.\n","\n","# =================================================== #\n","# =================================================== #\n","# ====== 모델링 할 때는 포함, 시험 볼때는 제거 ====== #\n","# 텐서플로우 버전 충돌로 인하여 \n","# 반드시 tensorflow 버전을 2.1.0 버전 설치 후 \n","# 모델작업 진행 해주셔야 합니다.\n","# 시험보실 때는 아래 \n","# !pip install tensorflow==2.1.0 명령어 필요 없습니다\n","# 텐서플로우 2.1.0 버전 재설치 코드\n","!pip install tensorflow==2.1.0\n","\n","# ====== 모델링 할 때는 포함, 시험 볼때는 제거 ====== #\n","# =================================================== #\n","\n","# =========== 합격 기준 가이드라인 공유 ============= #\n","# val_loss 기준에 맞춰 주시는 것이 훨씬 더 중요 #\n","# val_loss 보다 조금 높아도 상관없음. (언저리까지 OK) #\n","# =================================================== #\n","# 문제명: Category 3 - rps\n","# val_loss: 0.0871\n","# val_acc: 0.97\n","# =================================================== #\n","# =================================================== #\n","\n","import urllib.request\n","import zipfile\n","import tensorflow as tf\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Dense, Flatten, Dropout, Conv2D, MaxPooling2D\n","from tensorflow.keras.callbacks import ModelCheckpoint\n","\n","def solution_model():\n","    url = 'https://storage.googleapis.com/download.tensorflow.org/data/rps.zip'\n","    urllib.request.urlretrieve(url, 'rps.zip')\n","    local_zip = 'rps.zip'\n","    zip_ref = zipfile.ZipFile(local_zip, 'r')\n","    zip_ref.extractall('tmp/')\n","    zip_ref.close()\n","\n","\n","    TRAINING_DIR = \"tmp/rps/\"\n","    # YOUR CODE HERE)\n","    training_datagen = ImageDataGenerator(\n","      rescale=1. / 255,\n","      rotation_range=40,\n","      width_shift_range=0.2,\n","      height_shift_range=0.2,\n","      shear_range=0.2,\n","      zoom_range=0.2,\n","      horizontal_flip=True,\n","      fill_mode='nearest', \n","      validation_split=0.2\n","      )\n","\n","    #train_generator = # YOUR CODE HERE\n","    training_generator = training_datagen.flow_from_directory(TRAINING_DIR, \n","                                                              batch_size=32, \n","                                                              target_size=(150, 150), \n","                                                              class_mode='categorical', \n","                                                              subset='training',\n","                                                            )\n","\n","    validation_generator = training_datagen.flow_from_directory(TRAINING_DIR, \n","                                                              batch_size=32, \n","                                                              target_size=(150, 150), \n","                                                              class_mode='categorical',\n","                                                              subset='validation', \n","                                                            )\n","\n","\n","    model = tf.keras.models.Sequential([\n","        Conv2D(64, (3, 3), activation='relu', input_shape=(150, 150, 3)),\n","        MaxPooling2D(2, 2), \n","        Conv2D(128, (3, 3), activation='relu'),\n","        Conv2D(128, (3, 3), activation='relu'),\n","        MaxPooling2D(2, 2), \n","        Conv2D(128, (3, 3), activation='relu'),\n","        Conv2D(128, (3, 3), activation='relu'),\n","        MaxPooling2D(2, 2), \n","        Conv2D(256, (3, 3), activation='relu'),\n","        Conv2D(256, (3, 3), activation='relu'),\n","        MaxPooling2D(2, 2), \n","        Flatten(), \n","        Dropout(0.5),\n","        Dense(128, activation='relu'),\n","        Dense(64, activation='relu'),\n","\n","    # YOUR CODE HERE, BUT END WITH A 3 Neuron Dense, activated by softmax\n","        tf.keras.layers.Dense(3, activation='softmax')\n","    ])\n","    model.summary()\n","    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['acc'])\n","\n","    checkpoint_path = \"tmp_checkpoint.ckpt\"\n","    checkpoint = ModelCheckpoint(filepath=checkpoint_path, \n","                                save_weights_only=True, \n","                                save_best_only=True, \n","                                monitor='val_loss', \n","                                verbose=1)\n","\n","    model.fit(training_generator, \n","                        validation_data=(validation_generator),\n","                        epochs=20,\n","                        callbacks=[checkpoint],\n","                        )\n","\n","    model.load_weights(checkpoint_path)\n","\n","    return model\n","\n","\n","\n","# Note that you'll need to save your model as a .h5 like this\n","# This .h5 will be uploaded to the testing infrastructure\n","# and a score will be returned to you\n","if __name__ == '__main__':\n","    model = solution_model()\n","    model.save(\"TF3-rps.h5\")\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: tensorflow==2.1.0 in /usr/local/lib/python3.6/dist-packages (2.1.0)\n","Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0) (0.8.1)\n","Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0) (3.3.0)\n","Requirement already satisfied: tensorboard<2.2.0,>=2.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0) (2.1.1)\n","Requirement already satisfied: gast==0.2.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0) (0.2.2)\n","Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0) (1.31.0)\n","Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0) (0.2.0)\n","Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0) (0.8.1)\n","Requirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0) (3.12.4)\n","Requirement already satisfied: scipy==1.4.1; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0) (1.4.1)\n","Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0) (0.35.1)\n","Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0) (1.15.0)\n","Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0) (1.1.0)\n","Requirement already satisfied: tensorflow-estimator<2.2.0,>=2.1.0rc0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0) (2.1.0)\n","Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0) (1.12.1)\n","Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0) (1.18.5)\n","Requirement already satisfied: keras-preprocessing>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0) (1.1.2)\n","Requirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.1.0) (1.0.8)\n","Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (2.23.0)\n","Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (49.6.0)\n","Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (0.4.1)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (3.2.2)\n","Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (1.0.1)\n","Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (1.17.2)\n","Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.8->tensorflow==2.1.0) (2.10.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (2020.6.20)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (2.10)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (1.24.3)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (3.0.4)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (1.3.0)\n","Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (1.7.0)\n","Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (4.6)\n","Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (4.1.1)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (0.2.8)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (3.1.0)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (3.1.0)\n","Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.6/dist-packages (from rsa<5,>=3.1.4; python_version >= \"3\"->google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow==2.1.0) (0.4.8)\n","Found 2016 images belonging to 3 classes.\n","Found 504 images belonging to 3 classes.\n","Model: \"sequential_4\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","conv2d_21 (Conv2D)           (None, 148, 148, 64)      1792      \n","_________________________________________________________________\n","max_pooling2d_16 (MaxPooling (None, 74, 74, 64)        0         \n","_________________________________________________________________\n","conv2d_22 (Conv2D)           (None, 72, 72, 128)       73856     \n","_________________________________________________________________\n","conv2d_23 (Conv2D)           (None, 70, 70, 128)       147584    \n","_________________________________________________________________\n","max_pooling2d_17 (MaxPooling (None, 35, 35, 128)       0         \n","_________________________________________________________________\n","conv2d_24 (Conv2D)           (None, 33, 33, 128)       147584    \n","_________________________________________________________________\n","conv2d_25 (Conv2D)           (None, 31, 31, 128)       147584    \n","_________________________________________________________________\n","max_pooling2d_18 (MaxPooling (None, 15, 15, 128)       0         \n","_________________________________________________________________\n","conv2d_26 (Conv2D)           (None, 13, 13, 256)       295168    \n","_________________________________________________________________\n","conv2d_27 (Conv2D)           (None, 11, 11, 256)       590080    \n","_________________________________________________________________\n","max_pooling2d_19 (MaxPooling (None, 5, 5, 256)         0         \n","_________________________________________________________________\n","flatten_4 (Flatten)          (None, 6400)              0         \n","_________________________________________________________________\n","dropout_4 (Dropout)          (None, 6400)              0         \n","_________________________________________________________________\n","dense_10 (Dense)             (None, 128)               819328    \n","_________________________________________________________________\n","dense_11 (Dense)             (None, 64)                8256      \n","_________________________________________________________________\n","dense_12 (Dense)             (None, 3)                 195       \n","=================================================================\n","Total params: 2,231,427\n","Trainable params: 2,231,427\n","Non-trainable params: 0\n","_________________________________________________________________\n","WARNING:tensorflow:sample_weight modes were coerced from\n","  ...\n","    to  \n","  ['...']\n","WARNING:tensorflow:sample_weight modes were coerced from\n","  ...\n","    to  \n","  ['...']\n","Train for 63 steps, validate for 16 steps\n","Epoch 1/20\n","62/63 [============================>.] - ETA: 0s - loss: 1.1004 - acc: 0.3357\n","Epoch 00001: val_loss improved from inf to 1.09866, saving model to tmp_checkpoint.ckpt\n","63/63 [==============================] - 28s 440ms/step - loss: 1.1004 - acc: 0.3343 - val_loss: 1.0987 - val_acc: 0.3333\n","Epoch 2/20\n","62/63 [============================>.] - ETA: 0s - loss: 1.0988 - acc: 0.3357\n","Epoch 00002: val_loss improved from 1.09866 to 1.09862, saving model to tmp_checkpoint.ckpt\n","63/63 [==============================] - 25s 395ms/step - loss: 1.0988 - acc: 0.3348 - val_loss: 1.0986 - val_acc: 0.3333\n","Epoch 3/20\n","62/63 [============================>.] - ETA: 0s - loss: 1.0991 - acc: 0.3266\n","Epoch 00003: val_loss improved from 1.09862 to 1.09862, saving model to tmp_checkpoint.ckpt\n","63/63 [==============================] - 25s 394ms/step - loss: 1.0991 - acc: 0.3249 - val_loss: 1.0986 - val_acc: 0.3333\n","Epoch 4/20\n","62/63 [============================>.] - ETA: 0s - loss: 1.0990 - acc: 0.3140\n","Epoch 00004: val_loss improved from 1.09862 to 1.09861, saving model to tmp_checkpoint.ckpt\n","63/63 [==============================] - 25s 391ms/step - loss: 1.0990 - acc: 0.3145 - val_loss: 1.0986 - val_acc: 0.3333\n","Epoch 5/20\n","62/63 [============================>.] - ETA: 0s - loss: 1.0988 - acc: 0.3206\n","Epoch 00005: val_loss did not improve from 1.09861\n","63/63 [==============================] - 25s 393ms/step - loss: 1.0988 - acc: 0.3209 - val_loss: 1.0986 - val_acc: 0.3333\n","Epoch 6/20\n","62/63 [============================>.] - ETA: 0s - loss: 1.0988 - acc: 0.3281\n","Epoch 00006: val_loss did not improve from 1.09861\n","63/63 [==============================] - 25s 392ms/step - loss: 1.0988 - acc: 0.3284 - val_loss: 1.0986 - val_acc: 0.3333\n","Epoch 7/20\n","62/63 [============================>.] - ETA: 0s - loss: 1.0988 - acc: 0.3337\n","Epoch 00007: val_loss did not improve from 1.09861\n","63/63 [==============================] - 25s 392ms/step - loss: 1.0988 - acc: 0.3333 - val_loss: 1.0986 - val_acc: 0.3333\n","Epoch 8/20\n","62/63 [============================>.] - ETA: 0s - loss: 1.0987 - acc: 0.3317\n","Epoch 00008: val_loss improved from 1.09861 to 1.09861, saving model to tmp_checkpoint.ckpt\n","63/63 [==============================] - 25s 395ms/step - loss: 1.0987 - acc: 0.3313 - val_loss: 1.0986 - val_acc: 0.3333\n","Epoch 9/20\n","62/63 [============================>.] - ETA: 0s - loss: 1.0988 - acc: 0.3201\n","Epoch 00009: val_loss improved from 1.09861 to 1.09861, saving model to tmp_checkpoint.ckpt\n","63/63 [==============================] - 25s 394ms/step - loss: 1.0988 - acc: 0.3204 - val_loss: 1.0986 - val_acc: 0.3333\n","Epoch 10/20\n","62/63 [============================>.] - ETA: 0s - loss: 1.0988 - acc: 0.3216\n","Epoch 00010: val_loss did not improve from 1.09861\n","63/63 [==============================] - 25s 391ms/step - loss: 1.0988 - acc: 0.3219 - val_loss: 1.0986 - val_acc: 0.3333\n","Epoch 11/20\n","62/63 [============================>.] - ETA: 0s - loss: 1.0987 - acc: 0.3332\n","Epoch 00011: val_loss did not improve from 1.09861\n","63/63 [==============================] - 25s 392ms/step - loss: 1.0987 - acc: 0.3333 - val_loss: 1.0986 - val_acc: 0.3333\n","Epoch 12/20\n","62/63 [============================>.] - ETA: 0s - loss: 1.0987 - acc: 0.3322\n","Epoch 00012: val_loss did not improve from 1.09861\n","63/63 [==============================] - 25s 392ms/step - loss: 1.0987 - acc: 0.3309 - val_loss: 1.0986 - val_acc: 0.3333\n","Epoch 13/20\n","62/63 [============================>.] - ETA: 0s - loss: 1.0988 - acc: 0.3191\n","Epoch 00013: val_loss did not improve from 1.09861\n","63/63 [==============================] - 25s 392ms/step - loss: 1.0988 - acc: 0.3175 - val_loss: 1.0986 - val_acc: 0.3333\n","Epoch 14/20\n","62/63 [============================>.] - ETA: 0s - loss: 1.0987 - acc: 0.3201\n","Epoch 00014: val_loss did not improve from 1.09861\n","63/63 [==============================] - 25s 393ms/step - loss: 1.0987 - acc: 0.3199 - val_loss: 1.0986 - val_acc: 0.3333\n","Epoch 15/20\n","62/63 [============================>.] - ETA: 0s - loss: 1.0987 - acc: 0.3226\n","Epoch 00015: val_loss did not improve from 1.09861\n","63/63 [==============================] - 25s 395ms/step - loss: 1.0987 - acc: 0.3239 - val_loss: 1.0986 - val_acc: 0.3333\n","Epoch 16/20\n","62/63 [============================>.] - ETA: 0s - loss: 1.0988 - acc: 0.3211\n","Epoch 00016: val_loss did not improve from 1.09861\n","63/63 [==============================] - 25s 394ms/step - loss: 1.0988 - acc: 0.3209 - val_loss: 1.0986 - val_acc: 0.3333\n","Epoch 17/20\n","35/63 [===============>..............] - ETA: 9s - loss: 1.0986 - acc: 0.3511WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"],"name":"stdout"},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-6-8e9149bce0db>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    139\u001b[0m \u001b[0;31m# and a score will be returned to you\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'__main__'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msolution_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    142\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"TF3-rps.h5\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-6-8e9149bce0db>\u001b[0m in \u001b[0;36msolution_model\u001b[0;34m()\u001b[0m\n\u001b[1;32m    126\u001b[0m                         \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalidation_generator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m                         \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m                         \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcheckpoint\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    129\u001b[0m                         )\n\u001b[1;32m    130\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    817\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    818\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 819\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    820\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    821\u001b[0m   def evaluate(self,\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    340\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m                 \u001b[0mtraining_context\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining_context\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 342\u001b[0;31m                 total_epochs=epochs)\n\u001b[0m\u001b[1;32m    343\u001b[0m             \u001b[0mcbks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_logs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_result\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mrun_one_epoch\u001b[0;34m(model, iterator, execution_function, dataset_size, batch_size, strategy, steps_per_epoch, num_samples, mode, training_context, total_epochs)\u001b[0m\n\u001b[1;32m    126\u001b[0m         step=step, mode=mode, size=current_batch_size) as batch_logs:\n\u001b[1;32m    127\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    129\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mStopIteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m         \u001b[0;31m# TODO(kaftan): File bug about tf function and errors.OutOfRangeError?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training_v2_utils.py\u001b[0m in \u001b[0;36mexecution_function\u001b[0;34m(input_fn)\u001b[0m\n\u001b[1;32m     96\u001b[0m     \u001b[0;31m# `numpy` translates Tensors to values in Eager mode.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m     return nest.map_structure(_non_none_constant_value,\n\u001b[0;32m---> 98\u001b[0;31m                               distributed_function(input_fn))\n\u001b[0m\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    566\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    567\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 568\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    569\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    570\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    597\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    598\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 599\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    600\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    601\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2361\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2362\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2363\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2365\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   1609\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[1;32m   1610\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[0;32m-> 1611\u001b[0;31m         self.captured_inputs)\n\u001b[0m\u001b[1;32m   1612\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1613\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1690\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1691\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1692\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1693\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1694\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    543\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"executor_type\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"config_proto\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 545\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    546\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    547\u001b[0m           outputs = execute.execute_with_cancellation(\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tensorflow.TFE_Py_Execute(ctx._handle, device_name,\n\u001b[1;32m     60\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m                                                num_outputs)\n\u001b[0m\u001b[1;32m     62\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","metadata":{"id":"cZcBL4ig8_PY","colab_type":"code","colab":{}},"source":[""],"execution_count":null,"outputs":[]}]}